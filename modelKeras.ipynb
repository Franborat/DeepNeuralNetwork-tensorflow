{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute when using Colab for loading the dataset from my Github account and creating the different subsets\n",
    "\n",
    "'''\n",
    "! git clone https://github.com/Franborat/ml-datasets.git\n",
    "  \n",
    "! cd ml-datasets/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ATT_FILE = \"MedianHouseValuePreparedCleanAttributes.csv\"\n",
    "LABEL_FILE = \"MedianHouseValueOneHotEncodedClasses.csv\"\n",
    "\n",
    "TRAIN_RATE = 0.8\n",
    "\n",
    "attributes = pd.read_csv(ATT_FILE)\n",
    "label = pd.read_csv(LABEL_FILE)\n",
    "\n",
    "n_instances = attributes.shape[0]\n",
    "n_train = int(n_instances*TRAIN_RATE)\n",
    "n_dev = int((n_instances-n_train)/2)\n",
    "n_test = n_instances-n_train-n_dev\n",
    "\n",
    "x_train = attributes.values[:n_train]\n",
    "t_train = label.values[:n_train]\n",
    "\n",
    "x_dev = attributes.values[n_train:n_train+n_dev]\n",
    "t_dev = label.values[n_train:n_train+n_dev]\n",
    "\n",
    "x_test = attributes.values[n_train+n_dev:n_instances]\n",
    "t_test = label.values[n_train+n_dev:n_instances]\n",
    "\n",
    "print (\"x_train:\",x_train.shape)\n",
    "print (\"t_train:\",t_train.shape)\n",
    "\n",
    "print (\"x_dev:\",x_dev.shape)\n",
    "print (\"t_dev:\",t_dev.shape)\n",
    "\n",
    "print (\"x_test:\",x_test.shape)\n",
    "print (\"t_test:\",t_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "%run 1.ReadingData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = x_train.shape[1]\n",
    "OUTPUTS = t_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(x_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int (round (x_dev.shape[0]/1))\n",
    "NUM_TEST_EXAMPLES = int (round (x_test.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "dense_layers = [1,2,3]\n",
    "learning_rates = [0.001]\n",
    "#learning_rates = [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
    "batch_sizes = [32]\n",
    "#dropout_rates = [0.1,0.2,0.3,0.4,0.5]\n",
    "dropout_rates = [0.2]\n",
    "neurons = [64]\n",
    "\n",
    "# EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch with TensorBoard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    # All combinations available\n",
    "    layer_neurons = list(product(neurons, repeat=dense_layer))\n",
    "    for layer_neuron in layer_neurons:\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    \n",
    "                    mlp = Sequential()\n",
    "                    \n",
    "                    mlp.add(Dense(layer_neuron[0], input_dim=INPUTS))\n",
    "                    mlp.add(Activation('relu'))\n",
    "                    mlp.add(Dropout(0.2))\n",
    "                    \n",
    "                    if(dense_layer==1):\n",
    "                        NAME = \"{}x-Arquitecture-{}\".format(layer_neuron[0], int(time()))\n",
    "                    if(dense_layer==2):\n",
    "                        NAME = \"{}x{}x-Arquitecture-{}\".format(layer_neuron[0], layer_neuron[1], int(time()))\n",
    "                    if(dense_layer==3):\n",
    "                        NAME = \"{}x{}x{}-Arquitecture-{}\".format(layer_neuron[0], layer_neuron[1], layer_neuron[2], int(time()))\n",
    "                    print(NAME)\n",
    "\n",
    "                    for layer in range(dense_layer-1):\n",
    "                        print(\"------{}\".format(layer))\n",
    "                        mlp.add(Dense(layer_neuron[layer+1]))\n",
    "                        mlp.add(Activation('relu'))\n",
    "                        mlp.add(Dropout(0.2))  \n",
    "                        \n",
    "                    # Final layer\n",
    "                    mlp.add(Dense(OUTPUTS))\n",
    "                    mlp.add(Dropout(0.2))\n",
    "                    mlp.add(Activation('softmax'))\n",
    "                    \n",
    "                    tensorboard = TensorBoard(log_dir=\"Arquitecture-tuning/{}\".format(NAME))\n",
    "                    \n",
    "                    \n",
    "                    opt = optimizers.Adam(lr=learning_rate)\n",
    "                    mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    mlp.summary()    \n",
    "                    mlp.fit(x_train, t_train, batch_size=batch_size, epochs=50, verbose=2, validation_data=(x_dev, t_dev), callbacks=[tensorboard, earlystop])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute when using Colab to Download Tensorboard files\n",
    "\n",
    "'''\n",
    "!zip -r Final100.zip Arquitecture-tuning-weirds\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"Final100.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "loss, acc = mlp.evaluate(x_test, t_test, verbose=0)\n",
    "end = time()\n",
    "print('MLP took ' + str(end - start) + ' seconds')\n",
    "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
