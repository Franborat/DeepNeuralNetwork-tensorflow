{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (16346, 8)\n",
      "t_train: (16346, 10)\n",
      "x_dev: (2043, 8)\n",
      "t_dev: (2043, 10)\n",
      "x_test: (2044, 8)\n",
      "t_test: (2044, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "%run 1.ReadingData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = x_train.shape[1]\n",
    "OUTPUTS = t_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(x_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int (round (x_dev.shape[0]/1))\n",
    "NUM_TEST_EXAMPLES = int (round (x_test.shape[0]/1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexamples = [1, 2, 3]\\nfor example in examples:\\n    for l in range(example):\\n        print(\"Hola\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "examples = [1, 2, 3]\n",
    "for example in examples:\n",
    "    for l in range(example):\n",
    "        print(\"Hola\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch with TensorBoard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-dense-64-nodes-0.001-learning_rate-2-batch_size-1554668499\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 21s - loss: 1.7965 - acc: 0.2911 - val_loss: 1.7020 - val_acc: 0.3270\n",
      "Epoch 2/300\n",
      " - 18s - loss: 1.6912 - acc: 0.3332 - val_loss: 1.6400 - val_acc: 0.3426\n",
      "Epoch 3/300\n",
      " - 18s - loss: 1.6544 - acc: 0.3427 - val_loss: 1.6093 - val_acc: 0.3549\n",
      "Epoch 4/300\n",
      " - 18s - loss: 1.6321 - acc: 0.3535 - val_loss: 1.5919 - val_acc: 0.3823\n",
      "Epoch 5/300\n",
      " - 18s - loss: 1.6173 - acc: 0.3547 - val_loss: 1.5824 - val_acc: 0.3671\n",
      "Epoch 6/300\n",
      " - 18s - loss: 1.6080 - acc: 0.3581 - val_loss: 1.6904 - val_acc: 0.3377\n",
      "Epoch 7/300\n",
      " - 18s - loss: 1.5911 - acc: 0.3694 - val_loss: 1.6690 - val_acc: 0.3519\n",
      "Epoch 8/300\n",
      " - 18s - loss: 1.5829 - acc: 0.3687 - val_loss: 1.5608 - val_acc: 0.3852\n",
      "Epoch 9/300\n",
      " - 18s - loss: 1.5757 - acc: 0.3689 - val_loss: 1.5366 - val_acc: 0.4048\n",
      "Epoch 10/300\n",
      " - 18s - loss: 1.5614 - acc: 0.3788 - val_loss: 1.5460 - val_acc: 0.3955\n",
      "Epoch 11/300\n",
      " - 18s - loss: 1.5573 - acc: 0.3827 - val_loss: 1.5523 - val_acc: 0.3896\n",
      "Epoch 12/300\n",
      " - 18s - loss: 1.5522 - acc: 0.3847 - val_loss: 1.5518 - val_acc: 0.3872\n",
      "Epoch 13/300\n",
      " - 18s - loss: 1.5430 - acc: 0.3887 - val_loss: 1.5565 - val_acc: 0.3735\n",
      "Epoch 14/300\n",
      " - 18s - loss: 1.5374 - acc: 0.3880 - val_loss: 1.6076 - val_acc: 0.3656\n",
      "Epoch 15/300\n",
      " - 18s - loss: 1.5291 - acc: 0.3910 - val_loss: 1.5108 - val_acc: 0.4112\n",
      "Epoch 16/300\n",
      " - 18s - loss: 1.5229 - acc: 0.3916 - val_loss: 1.5089 - val_acc: 0.4097\n",
      "Epoch 17/300\n",
      " - 18s - loss: 1.5183 - acc: 0.3975 - val_loss: 1.5389 - val_acc: 0.3896\n",
      "Epoch 18/300\n",
      " - 18s - loss: 1.5071 - acc: 0.3965 - val_loss: 1.5393 - val_acc: 0.3970\n",
      "Epoch 19/300\n",
      " - 18s - loss: 1.5058 - acc: 0.4017 - val_loss: 1.4973 - val_acc: 0.4043\n",
      "Epoch 20/300\n",
      " - 18s - loss: 1.4995 - acc: 0.4029 - val_loss: 1.4962 - val_acc: 0.4161\n",
      "Epoch 21/300\n",
      " - 19s - loss: 1.4925 - acc: 0.4060 - val_loss: 1.5241 - val_acc: 0.3965\n",
      "Epoch 22/300\n",
      " - 19s - loss: 1.4854 - acc: 0.4078 - val_loss: 1.5485 - val_acc: 0.3965\n",
      "Epoch 23/300\n",
      " - 18s - loss: 1.4825 - acc: 0.4071 - val_loss: 1.5424 - val_acc: 0.4126\n",
      "Epoch 24/300\n",
      " - 18s - loss: 1.4789 - acc: 0.4111 - val_loss: 1.5228 - val_acc: 0.4288\n",
      "Epoch 25/300\n",
      " - 18s - loss: 1.4755 - acc: 0.4117 - val_loss: 1.4781 - val_acc: 0.4087\n",
      "Epoch 26/300\n",
      " - 18s - loss: 1.4688 - acc: 0.4161 - val_loss: 1.4964 - val_acc: 0.4244\n",
      "Epoch 27/300\n",
      " - 18s - loss: 1.4645 - acc: 0.4181 - val_loss: 1.5209 - val_acc: 0.4121\n",
      "Epoch 28/300\n",
      " - 18s - loss: 1.4591 - acc: 0.4218 - val_loss: 1.5049 - val_acc: 0.4156\n",
      "Epoch 29/300\n",
      " - 18s - loss: 1.4559 - acc: 0.4191 - val_loss: 1.4738 - val_acc: 0.4141\n",
      "Epoch 30/300\n",
      " - 18s - loss: 1.4481 - acc: 0.4195 - val_loss: 1.4907 - val_acc: 0.4136\n",
      "Epoch 31/300\n",
      " - 18s - loss: 1.4453 - acc: 0.4208 - val_loss: 1.4646 - val_acc: 0.4351\n",
      "Epoch 32/300\n",
      " - 18s - loss: 1.4421 - acc: 0.4199 - val_loss: 1.4830 - val_acc: 0.4327\n",
      "Epoch 33/300\n",
      " - 18s - loss: 1.4407 - acc: 0.4237 - val_loss: 1.4671 - val_acc: 0.4395\n",
      "Epoch 34/300\n",
      " - 18s - loss: 1.4295 - acc: 0.4271 - val_loss: 1.5110 - val_acc: 0.4185\n",
      "Epoch 35/300\n",
      " - 18s - loss: 1.4287 - acc: 0.4304 - val_loss: 1.5148 - val_acc: 0.4048\n",
      "Epoch 36/300\n",
      " - 18s - loss: 1.4286 - acc: 0.4323 - val_loss: 1.4883 - val_acc: 0.4209\n",
      "Epoch 37/300\n",
      " - 2223s - loss: 1.4259 - acc: 0.4314 - val_loss: 1.5311 - val_acc: 0.4009\n",
      "Epoch 38/300\n",
      " - 28s - loss: 1.4205 - acc: 0.4317 - val_loss: 1.4983 - val_acc: 0.4425\n",
      "Epoch 39/300\n",
      " - 21s - loss: 1.4147 - acc: 0.4318 - val_loss: 1.5360 - val_acc: 0.4263\n",
      "Epoch 40/300\n",
      " - 113s - loss: 1.4115 - acc: 0.4367 - val_loss: 1.5502 - val_acc: 0.4190\n",
      "Epoch 41/300\n",
      " - 20s - loss: 1.4114 - acc: 0.4336 - val_loss: 1.5040 - val_acc: 0.4185\n",
      "Epoch 42/300\n",
      " - 2219s - loss: 1.4058 - acc: 0.4369 - val_loss: 1.4911 - val_acc: 0.4229\n",
      "Epoch 43/300\n",
      " - 20s - loss: 1.4055 - acc: 0.4359 - val_loss: 1.4779 - val_acc: 0.4219\n",
      "Epoch 44/300\n",
      " - 615s - loss: 1.4058 - acc: 0.4354 - val_loss: 1.4679 - val_acc: 0.4425\n",
      "Epoch 45/300\n",
      " - 22s - loss: 1.4024 - acc: 0.4394 - val_loss: 1.5045 - val_acc: 0.4234\n",
      "Epoch 46/300\n",
      " - 19s - loss: 1.3985 - acc: 0.4435 - val_loss: 1.4805 - val_acc: 0.4185\n",
      "Epoch 47/300\n",
      " - 19s - loss: 1.3939 - acc: 0.4411 - val_loss: 1.4833 - val_acc: 0.4302\n",
      "Epoch 48/300\n",
      " - 19s - loss: 1.3930 - acc: 0.4439 - val_loss: 1.5165 - val_acc: 0.4200\n",
      "3-dense-64-nodes-0.001-learning_rate-4-batch_size-1554674490\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 11s - loss: 1.8008 - acc: 0.2963 - val_loss: 1.6751 - val_acc: 0.3343\n",
      "Epoch 2/300\n",
      " - 11s - loss: 1.6907 - acc: 0.3278 - val_loss: 1.6316 - val_acc: 0.3519\n",
      "Epoch 3/300\n",
      " - 10s - loss: 1.6496 - acc: 0.3424 - val_loss: 1.6090 - val_acc: 0.3549\n",
      "Epoch 4/300\n",
      " - 11s - loss: 1.6318 - acc: 0.3563 - val_loss: 1.6057 - val_acc: 0.3637\n",
      "Epoch 5/300\n",
      " - 10s - loss: 1.6167 - acc: 0.3548 - val_loss: 1.5945 - val_acc: 0.3593\n",
      "Epoch 6/300\n",
      " - 10s - loss: 1.6023 - acc: 0.3594 - val_loss: 1.5662 - val_acc: 0.4009\n",
      "Epoch 7/300\n",
      " - 9s - loss: 1.5919 - acc: 0.3642 - val_loss: 1.5566 - val_acc: 0.3798\n",
      "Epoch 8/300\n",
      " - 9s - loss: 1.5816 - acc: 0.3732 - val_loss: 1.6574 - val_acc: 0.3563\n",
      "Epoch 9/300\n",
      " - 9s - loss: 1.5752 - acc: 0.3721 - val_loss: 1.5663 - val_acc: 0.3764\n",
      "Epoch 10/300\n",
      " - 9s - loss: 1.5666 - acc: 0.3727 - val_loss: 1.5494 - val_acc: 0.3896\n",
      "Epoch 11/300\n",
      " - 9s - loss: 1.5581 - acc: 0.3784 - val_loss: 1.5237 - val_acc: 0.3842\n",
      "Epoch 12/300\n",
      " - 10s - loss: 1.5487 - acc: 0.3828 - val_loss: 1.5370 - val_acc: 0.3793\n",
      "Epoch 13/300\n",
      " - 11s - loss: 1.5402 - acc: 0.3833 - val_loss: 1.5264 - val_acc: 0.3940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      " - 11s - loss: 1.5339 - acc: 0.3904 - val_loss: 1.6511 - val_acc: 0.3377\n",
      "Epoch 15/300\n",
      " - 12s - loss: 1.5233 - acc: 0.3939 - val_loss: 1.5269 - val_acc: 0.4058\n",
      "Epoch 16/300\n",
      " - 11s - loss: 1.5162 - acc: 0.3929 - val_loss: 1.4985 - val_acc: 0.4014\n",
      "Epoch 17/300\n",
      " - 10s - loss: 1.5112 - acc: 0.3995 - val_loss: 1.5709 - val_acc: 0.3911\n",
      "Epoch 18/300\n",
      " - 9s - loss: 1.5086 - acc: 0.4010 - val_loss: 1.5023 - val_acc: 0.4190\n",
      "Epoch 19/300\n",
      " - 9s - loss: 1.5002 - acc: 0.4010 - val_loss: 1.4936 - val_acc: 0.3970\n",
      "Epoch 20/300\n",
      " - 9s - loss: 1.4939 - acc: 0.4036 - val_loss: 1.4679 - val_acc: 0.4244\n",
      "Epoch 21/300\n",
      " - 9s - loss: 1.4864 - acc: 0.4125 - val_loss: 1.4954 - val_acc: 0.4023\n",
      "Epoch 22/300\n",
      " - 9s - loss: 1.4791 - acc: 0.4074 - val_loss: 1.4673 - val_acc: 0.4161\n",
      "Epoch 23/300\n",
      " - 10s - loss: 1.4750 - acc: 0.4131 - val_loss: 1.4681 - val_acc: 0.4200\n",
      "Epoch 24/300\n",
      " - 11s - loss: 1.4730 - acc: 0.4080 - val_loss: 1.4797 - val_acc: 0.4190\n",
      "Epoch 25/300\n",
      " - 9s - loss: 1.4671 - acc: 0.4116 - val_loss: 1.4782 - val_acc: 0.4043\n",
      "Epoch 26/300\n",
      " - 10s - loss: 1.4635 - acc: 0.4173 - val_loss: 1.4789 - val_acc: 0.4072\n",
      "Epoch 27/300\n",
      " - 10s - loss: 1.4548 - acc: 0.4194 - val_loss: 1.5711 - val_acc: 0.3833\n",
      "Epoch 28/300\n",
      " - 10s - loss: 1.4509 - acc: 0.4188 - val_loss: 1.5188 - val_acc: 0.4058\n",
      "Epoch 29/300\n",
      " - 10s - loss: 1.4454 - acc: 0.4209 - val_loss: 1.4569 - val_acc: 0.4116\n",
      "Epoch 30/300\n",
      " - 10s - loss: 1.4432 - acc: 0.4221 - val_loss: 1.4441 - val_acc: 0.4263\n",
      "Epoch 31/300\n",
      " - 10s - loss: 1.4340 - acc: 0.4257 - val_loss: 1.5427 - val_acc: 0.3921\n",
      "Epoch 32/300\n",
      " - 10s - loss: 1.4341 - acc: 0.4245 - val_loss: 1.4775 - val_acc: 0.4102\n",
      "Epoch 33/300\n",
      " - 10s - loss: 1.4286 - acc: 0.4286 - val_loss: 1.4626 - val_acc: 0.4278\n",
      "Epoch 34/300\n",
      " - 10s - loss: 1.4241 - acc: 0.4299 - val_loss: 1.4603 - val_acc: 0.4161\n",
      "Epoch 35/300\n",
      " - 10s - loss: 1.4216 - acc: 0.4278 - val_loss: 1.4167 - val_acc: 0.4366\n",
      "Epoch 36/300\n",
      " - 11s - loss: 1.4168 - acc: 0.4324 - val_loss: 1.4620 - val_acc: 0.4219\n",
      "Epoch 37/300\n",
      " - 10s - loss: 1.4112 - acc: 0.4373 - val_loss: 1.4501 - val_acc: 0.4278\n",
      "Epoch 38/300\n",
      " - 10s - loss: 1.4095 - acc: 0.4380 - val_loss: 1.6014 - val_acc: 0.3784\n",
      "Epoch 39/300\n",
      " - 10s - loss: 1.4060 - acc: 0.4379 - val_loss: 1.4342 - val_acc: 0.4293\n",
      "Epoch 40/300\n",
      " - 10s - loss: 1.3992 - acc: 0.4436 - val_loss: 1.4234 - val_acc: 0.4430\n",
      "Epoch 41/300\n",
      " - 9s - loss: 1.3966 - acc: 0.4409 - val_loss: 1.4160 - val_acc: 0.4498\n",
      "Epoch 42/300\n",
      " - 9s - loss: 1.3896 - acc: 0.4455 - val_loss: 1.4271 - val_acc: 0.4400\n",
      "Epoch 43/300\n",
      " - 10s - loss: 1.3861 - acc: 0.4446 - val_loss: 1.4658 - val_acc: 0.4165\n",
      "Epoch 44/300\n",
      " - 10s - loss: 1.3810 - acc: 0.4476 - val_loss: 1.4075 - val_acc: 0.4488\n",
      "Epoch 45/300\n",
      " - 11s - loss: 1.3797 - acc: 0.4504 - val_loss: 1.4330 - val_acc: 0.4312\n",
      "Epoch 46/300\n",
      " - 10s - loss: 1.3805 - acc: 0.4479 - val_loss: 1.4634 - val_acc: 0.4254\n",
      "Epoch 47/300\n",
      " - 10s - loss: 1.3741 - acc: 0.4488 - val_loss: 1.4224 - val_acc: 0.4391\n",
      "Epoch 48/300\n",
      " - 10s - loss: 1.3713 - acc: 0.4506 - val_loss: 1.4609 - val_acc: 0.4224\n",
      "Epoch 49/300\n",
      " - 10s - loss: 1.3724 - acc: 0.4487 - val_loss: 1.4407 - val_acc: 0.4317\n",
      "Epoch 50/300\n",
      " - 11s - loss: 1.3620 - acc: 0.4555 - val_loss: 1.4409 - val_acc: 0.4493\n",
      "Epoch 51/300\n",
      " - 11s - loss: 1.3643 - acc: 0.4561 - val_loss: 1.4332 - val_acc: 0.4376\n",
      "3-dense-64-nodes-0.001-learning_rate-8-batch_size-1554675002\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 6s - loss: 1.8057 - acc: 0.2931 - val_loss: 1.7364 - val_acc: 0.3103\n",
      "Epoch 2/300\n",
      " - 6s - loss: 1.6877 - acc: 0.3321 - val_loss: 1.6422 - val_acc: 0.3372\n",
      "Epoch 3/300\n",
      " - 5s - loss: 1.6501 - acc: 0.3457 - val_loss: 1.6132 - val_acc: 0.3583\n",
      "Epoch 4/300\n",
      " - 5s - loss: 1.6322 - acc: 0.3514 - val_loss: 1.5797 - val_acc: 0.3769\n",
      "Epoch 5/300\n",
      " - 5s - loss: 1.6184 - acc: 0.3578 - val_loss: 1.5942 - val_acc: 0.3647\n",
      "Epoch 6/300\n",
      " - 5s - loss: 1.6031 - acc: 0.3639 - val_loss: 1.5720 - val_acc: 0.3852\n",
      "Epoch 7/300\n",
      " - 5s - loss: 1.5993 - acc: 0.3612 - val_loss: 1.5843 - val_acc: 0.3681\n",
      "Epoch 8/300\n",
      " - 5s - loss: 1.5914 - acc: 0.3635 - val_loss: 1.6198 - val_acc: 0.3573\n",
      "Epoch 9/300\n",
      " - 5s - loss: 1.5774 - acc: 0.3740 - val_loss: 1.5809 - val_acc: 0.3700\n",
      "Epoch 10/300\n",
      " - 6s - loss: 1.5696 - acc: 0.3730 - val_loss: 1.5609 - val_acc: 0.3833\n",
      "Epoch 11/300\n",
      " - 5s - loss: 1.5616 - acc: 0.3857 - val_loss: 1.5589 - val_acc: 0.3789\n",
      "Epoch 12/300\n",
      " - 5s - loss: 1.5558 - acc: 0.3832 - val_loss: 1.5190 - val_acc: 0.4112\n",
      "Epoch 13/300\n",
      " - 6s - loss: 1.5441 - acc: 0.3863 - val_loss: 1.5666 - val_acc: 0.3744\n",
      "Epoch 14/300\n",
      " - 5s - loss: 1.5363 - acc: 0.3902 - val_loss: 1.5289 - val_acc: 0.3906\n",
      "Epoch 15/300\n",
      " - 5s - loss: 1.5268 - acc: 0.3912 - val_loss: 1.5276 - val_acc: 0.3921\n",
      "Epoch 16/300\n",
      " - 6s - loss: 1.5185 - acc: 0.3952 - val_loss: 1.5009 - val_acc: 0.4038\n",
      "Epoch 17/300\n",
      " - 6s - loss: 1.5107 - acc: 0.3963 - val_loss: 1.5086 - val_acc: 0.3979\n",
      "Epoch 18/300\n",
      " - 6s - loss: 1.4991 - acc: 0.4038 - val_loss: 1.5051 - val_acc: 0.3965\n",
      "Epoch 19/300\n",
      " - 5s - loss: 1.4912 - acc: 0.4068 - val_loss: 1.5285 - val_acc: 0.4082\n",
      "Epoch 20/300\n",
      " - 5s - loss: 1.4842 - acc: 0.4058 - val_loss: 1.4714 - val_acc: 0.4121\n",
      "Epoch 21/300\n",
      " - 5s - loss: 1.4745 - acc: 0.4125 - val_loss: 1.4829 - val_acc: 0.3994\n",
      "Epoch 22/300\n",
      " - 5s - loss: 1.4705 - acc: 0.4150 - val_loss: 1.4787 - val_acc: 0.4107\n",
      "Epoch 23/300\n",
      " - 5s - loss: 1.4644 - acc: 0.4201 - val_loss: 1.4536 - val_acc: 0.4219\n",
      "Epoch 24/300\n",
      " - 5s - loss: 1.4593 - acc: 0.4146 - val_loss: 1.4435 - val_acc: 0.4288\n",
      "Epoch 25/300\n",
      " - 5s - loss: 1.4567 - acc: 0.4179 - val_loss: 1.4877 - val_acc: 0.4048\n",
      "Epoch 26/300\n",
      " - 5s - loss: 1.4500 - acc: 0.4191 - val_loss: 1.4629 - val_acc: 0.4200\n",
      "Epoch 27/300\n",
      " - 5s - loss: 1.4460 - acc: 0.4227 - val_loss: 1.5082 - val_acc: 0.4014\n",
      "Epoch 28/300\n",
      " - 5s - loss: 1.4394 - acc: 0.4261 - val_loss: 1.4469 - val_acc: 0.4386\n",
      "Epoch 29/300\n",
      " - 5s - loss: 1.4337 - acc: 0.4289 - val_loss: 1.4491 - val_acc: 0.4209\n",
      "Epoch 30/300\n",
      " - 5s - loss: 1.4336 - acc: 0.4270 - val_loss: 1.4305 - val_acc: 0.4444\n",
      "Epoch 31/300\n",
      " - 5s - loss: 1.4263 - acc: 0.4305 - val_loss: 1.4912 - val_acc: 0.4116\n",
      "Epoch 32/300\n",
      " - 5s - loss: 1.4201 - acc: 0.4303 - val_loss: 1.4306 - val_acc: 0.4175\n",
      "Epoch 33/300\n",
      " - 5s - loss: 1.4150 - acc: 0.4345 - val_loss: 1.4353 - val_acc: 0.4234\n",
      "Epoch 34/300\n",
      " - 5s - loss: 1.4119 - acc: 0.4357 - val_loss: 1.4254 - val_acc: 0.4415\n",
      "Epoch 35/300\n",
      " - 5s - loss: 1.4061 - acc: 0.4381 - val_loss: 1.5152 - val_acc: 0.4087\n",
      "Epoch 36/300\n",
      " - 5s - loss: 1.4014 - acc: 0.4387 - val_loss: 1.4352 - val_acc: 0.4302\n",
      "Epoch 37/300\n",
      " - 5s - loss: 1.3991 - acc: 0.4427 - val_loss: 1.4214 - val_acc: 0.4302\n",
      "Epoch 38/300\n",
      " - 5s - loss: 1.3954 - acc: 0.4397 - val_loss: 1.4309 - val_acc: 0.4410\n",
      "Epoch 39/300\n",
      " - 5s - loss: 1.3890 - acc: 0.4467 - val_loss: 1.4546 - val_acc: 0.4205\n",
      "Epoch 40/300\n",
      " - 5s - loss: 1.3858 - acc: 0.4432 - val_loss: 1.4250 - val_acc: 0.4430\n",
      "3-dense-64-nodes-0.001-learning_rate-16-batch_size-1554675209\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 1.8305 - acc: 0.2892 - val_loss: 1.6880 - val_acc: 0.3333\n",
      "Epoch 2/300\n",
      " - 3s - loss: 1.6914 - acc: 0.3275 - val_loss: 1.6463 - val_acc: 0.3382\n",
      "Epoch 3/300\n",
      " - 3s - loss: 1.6518 - acc: 0.3457 - val_loss: 1.6080 - val_acc: 0.3715\n",
      "Epoch 4/300\n",
      " - 3s - loss: 1.6331 - acc: 0.3518 - val_loss: 1.6284 - val_acc: 0.3510\n",
      "Epoch 5/300\n",
      " - 3s - loss: 1.6266 - acc: 0.3561 - val_loss: 1.6184 - val_acc: 0.3539\n",
      "Epoch 6/300\n",
      " - 3s - loss: 1.6109 - acc: 0.3603 - val_loss: 1.5719 - val_acc: 0.3759\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6026 - acc: 0.3673 - val_loss: 1.5720 - val_acc: 0.3715\n",
      "Epoch 8/300\n",
      " - 3s - loss: 1.5893 - acc: 0.3702 - val_loss: 1.5618 - val_acc: 0.3779\n",
      "Epoch 9/300\n",
      " - 3s - loss: 1.5831 - acc: 0.3725 - val_loss: 1.5525 - val_acc: 0.3828\n",
      "Epoch 10/300\n",
      " - 3s - loss: 1.5748 - acc: 0.3742 - val_loss: 1.5920 - val_acc: 0.3681\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.5690 - acc: 0.3787 - val_loss: 1.5408 - val_acc: 0.3877\n",
      "Epoch 12/300\n",
      " - 3s - loss: 1.5609 - acc: 0.3795 - val_loss: 1.5350 - val_acc: 0.3852\n",
      "Epoch 13/300\n",
      " - 3s - loss: 1.5541 - acc: 0.3869 - val_loss: 1.5345 - val_acc: 0.4023\n",
      "Epoch 14/300\n",
      " - 3s - loss: 1.5445 - acc: 0.3907 - val_loss: 1.5542 - val_acc: 0.3833\n",
      "Epoch 15/300\n",
      " - 3s - loss: 1.5395 - acc: 0.3869 - val_loss: 1.5136 - val_acc: 0.4063\n",
      "Epoch 16/300\n",
      " - 3s - loss: 1.5330 - acc: 0.3929 - val_loss: 1.5372 - val_acc: 0.3911\n",
      "Epoch 17/300\n",
      " - 3s - loss: 1.5209 - acc: 0.3991 - val_loss: 1.5089 - val_acc: 0.4033\n",
      "Epoch 18/300\n",
      " - 3s - loss: 1.5179 - acc: 0.3958 - val_loss: 1.5365 - val_acc: 0.3896\n",
      "Epoch 19/300\n",
      " - 3s - loss: 1.5108 - acc: 0.3962 - val_loss: 1.5160 - val_acc: 0.3989\n",
      "Epoch 20/300\n",
      " - 3s - loss: 1.5098 - acc: 0.4000 - val_loss: 1.5118 - val_acc: 0.3979\n",
      "Epoch 21/300\n",
      " - 3s - loss: 1.5005 - acc: 0.4049 - val_loss: 1.5043 - val_acc: 0.3906\n",
      "Epoch 22/300\n",
      " - 3s - loss: 1.4974 - acc: 0.4068 - val_loss: 1.5360 - val_acc: 0.3960\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.4893 - acc: 0.4035 - val_loss: 1.4883 - val_acc: 0.4146\n",
      "Epoch 24/300\n",
      " - 3s - loss: 1.4854 - acc: 0.4107 - val_loss: 1.4711 - val_acc: 0.4082\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.4744 - acc: 0.4164 - val_loss: 1.4815 - val_acc: 0.4058\n",
      "Epoch 26/300\n",
      " - 3s - loss: 1.4687 - acc: 0.4180 - val_loss: 1.4816 - val_acc: 0.4151\n",
      "Epoch 27/300\n",
      " - 3s - loss: 1.4654 - acc: 0.4161 - val_loss: 1.4897 - val_acc: 0.4087\n",
      "Epoch 28/300\n",
      " - 3s - loss: 1.4601 - acc: 0.4174 - val_loss: 1.4957 - val_acc: 0.4170\n",
      "Epoch 29/300\n",
      " - 3s - loss: 1.4559 - acc: 0.4170 - val_loss: 1.4934 - val_acc: 0.3984\n",
      "Epoch 30/300\n",
      " - 3s - loss: 1.4523 - acc: 0.4203 - val_loss: 1.4822 - val_acc: 0.4151\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.4511 - acc: 0.4240 - val_loss: 1.4847 - val_acc: 0.4058\n",
      "Epoch 32/300\n",
      " - 3s - loss: 1.4429 - acc: 0.4260 - val_loss: 1.4485 - val_acc: 0.4161\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.4395 - acc: 0.4277 - val_loss: 1.4636 - val_acc: 0.4278\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.4314 - acc: 0.4309 - val_loss: 1.4488 - val_acc: 0.4239\n",
      "Epoch 35/300\n",
      " - 3s - loss: 1.4331 - acc: 0.4271 - val_loss: 1.4313 - val_acc: 0.4381\n",
      "Epoch 36/300\n",
      " - 3s - loss: 1.4272 - acc: 0.4339 - val_loss: 1.4481 - val_acc: 0.4258\n",
      "Epoch 37/300\n",
      " - 3s - loss: 1.4248 - acc: 0.4345 - val_loss: 1.4342 - val_acc: 0.4356\n",
      "Epoch 38/300\n",
      " - 3s - loss: 1.4171 - acc: 0.4375 - val_loss: 1.4688 - val_acc: 0.4273\n",
      "Epoch 39/300\n",
      " - 3s - loss: 1.4116 - acc: 0.4387 - val_loss: 1.4623 - val_acc: 0.4185\n",
      "Epoch 40/300\n",
      " - 3s - loss: 1.4148 - acc: 0.4382 - val_loss: 1.4768 - val_acc: 0.4224\n",
      "Epoch 41/300\n",
      " - 3s - loss: 1.4121 - acc: 0.4379 - val_loss: 1.4267 - val_acc: 0.4410\n",
      "Epoch 42/300\n",
      " - 3s - loss: 1.4025 - acc: 0.4416 - val_loss: 1.4155 - val_acc: 0.4474\n",
      "Epoch 43/300\n",
      " - 3s - loss: 1.4029 - acc: 0.4377 - val_loss: 1.5035 - val_acc: 0.4141\n",
      "Epoch 44/300\n",
      " - 2s - loss: 1.3979 - acc: 0.4405 - val_loss: 1.4658 - val_acc: 0.4180\n",
      "Epoch 45/300\n",
      " - 3s - loss: 1.3939 - acc: 0.4441 - val_loss: 1.4126 - val_acc: 0.4391\n",
      "Epoch 46/300\n",
      " - 2s - loss: 1.3919 - acc: 0.4468 - val_loss: 1.4273 - val_acc: 0.4391\n",
      "Epoch 47/300\n",
      " - 3s - loss: 1.3825 - acc: 0.4482 - val_loss: 1.4072 - val_acc: 0.4459\n",
      "Epoch 48/300\n",
      " - 2s - loss: 1.3862 - acc: 0.4523 - val_loss: 1.4219 - val_acc: 0.4351\n",
      "Epoch 49/300\n",
      " - 2s - loss: 1.3842 - acc: 0.4512 - val_loss: 1.4157 - val_acc: 0.4454\n",
      "Epoch 50/300\n",
      " - 3s - loss: 1.3900 - acc: 0.4457 - val_loss: 1.4764 - val_acc: 0.3999\n",
      "Epoch 51/300\n",
      " - 3s - loss: 1.3777 - acc: 0.4500 - val_loss: 1.4238 - val_acc: 0.4366\n",
      "Epoch 52/300\n",
      " - 3s - loss: 1.3786 - acc: 0.4482 - val_loss: 1.4255 - val_acc: 0.4224\n",
      "3-dense-64-nodes-0.001-learning_rate-32-batch_size-1554675352\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 1.8833 - acc: 0.2773 - val_loss: 1.7006 - val_acc: 0.3167\n",
      "Epoch 2/300\n",
      " - 2s - loss: 1.7221 - acc: 0.3250 - val_loss: 1.6979 - val_acc: 0.3211\n",
      "Epoch 3/300\n",
      " - 2s - loss: 1.6884 - acc: 0.3353 - val_loss: 1.6589 - val_acc: 0.3539\n",
      "Epoch 4/300\n",
      " - 2s - loss: 1.6623 - acc: 0.3452 - val_loss: 1.6378 - val_acc: 0.3465\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.6437 - acc: 0.3519 - val_loss: 1.6090 - val_acc: 0.3539\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.6331 - acc: 0.3508 - val_loss: 1.6024 - val_acc: 0.3671\n",
      "Epoch 7/300\n",
      " - 1s - loss: 1.6154 - acc: 0.3644 - val_loss: 1.6485 - val_acc: 0.3436\n",
      "Epoch 8/300\n",
      " - 1s - loss: 1.6090 - acc: 0.3648 - val_loss: 1.5792 - val_acc: 0.3715\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5973 - acc: 0.3661 - val_loss: 1.6017 - val_acc: 0.3715\n",
      "Epoch 10/300\n",
      " - 1s - loss: 1.5924 - acc: 0.3688 - val_loss: 1.5797 - val_acc: 0.3696\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.5819 - acc: 0.3768 - val_loss: 1.5646 - val_acc: 0.3764\n",
      "Epoch 12/300\n",
      " - 1s - loss: 1.5763 - acc: 0.3776 - val_loss: 1.5843 - val_acc: 0.3656\n",
      "Epoch 13/300\n",
      " - 1s - loss: 1.5687 - acc: 0.3765 - val_loss: 1.5665 - val_acc: 0.3813\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.5646 - acc: 0.3813 - val_loss: 1.5357 - val_acc: 0.3940\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.5564 - acc: 0.3862 - val_loss: 1.5315 - val_acc: 0.3950\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.5526 - acc: 0.3816 - val_loss: 1.5404 - val_acc: 0.3906\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.5484 - acc: 0.3856 - val_loss: 1.5853 - val_acc: 0.3710\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.5419 - acc: 0.3910 - val_loss: 1.5279 - val_acc: 0.3916\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.5374 - acc: 0.3900 - val_loss: 1.5503 - val_acc: 0.3837\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.5333 - acc: 0.3931 - val_loss: 1.5278 - val_acc: 0.3926\n",
      "Epoch 21/300\n",
      " - 1s - loss: 1.5238 - acc: 0.3957 - val_loss: 1.5108 - val_acc: 0.3882\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.5221 - acc: 0.3965 - val_loss: 1.5519 - val_acc: 0.3823\n",
      "Epoch 23/300\n",
      " - 1s - loss: 1.5228 - acc: 0.3932 - val_loss: 1.5347 - val_acc: 0.3891\n",
      "Epoch 24/300\n",
      " - 1s - loss: 1.5107 - acc: 0.4047 - val_loss: 1.5118 - val_acc: 0.4121\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.5076 - acc: 0.4004 - val_loss: 1.5049 - val_acc: 0.4151\n",
      "Epoch 26/300\n",
      " - 1s - loss: 1.5052 - acc: 0.4012 - val_loss: 1.5113 - val_acc: 0.4043\n",
      "Epoch 27/300\n",
      " - 1s - loss: 1.4958 - acc: 0.4057 - val_loss: 1.4902 - val_acc: 0.4077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/300\n",
      " - 1s - loss: 1.4960 - acc: 0.4044 - val_loss: 1.4856 - val_acc: 0.4131\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.4866 - acc: 0.4084 - val_loss: 1.4901 - val_acc: 0.4131\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.4892 - acc: 0.4084 - val_loss: 1.4807 - val_acc: 0.4180\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.4808 - acc: 0.4106 - val_loss: 1.5189 - val_acc: 0.4028\n",
      "Epoch 32/300\n",
      " - 1s - loss: 1.4736 - acc: 0.4155 - val_loss: 1.4886 - val_acc: 0.4136\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.4743 - acc: 0.4091 - val_loss: 1.5057 - val_acc: 0.4014\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.4670 - acc: 0.4178 - val_loss: 1.4861 - val_acc: 0.4229\n",
      "Epoch 35/300\n",
      " - 1s - loss: 1.4667 - acc: 0.4164 - val_loss: 1.4776 - val_acc: 0.4116\n",
      "Epoch 36/300\n",
      " - 1s - loss: 1.4597 - acc: 0.4177 - val_loss: 1.4703 - val_acc: 0.4224\n",
      "Epoch 37/300\n",
      " - 1s - loss: 1.4519 - acc: 0.4204 - val_loss: 1.4791 - val_acc: 0.4224\n",
      "Epoch 38/300\n",
      " - 1s - loss: 1.4478 - acc: 0.4220 - val_loss: 1.4701 - val_acc: 0.4165\n",
      "Epoch 39/300\n",
      " - 1s - loss: 1.4458 - acc: 0.4221 - val_loss: 1.4866 - val_acc: 0.4072\n",
      "Epoch 40/300\n",
      " - 1s - loss: 1.4433 - acc: 0.4321 - val_loss: 1.4841 - val_acc: 0.4097\n",
      "Epoch 41/300\n",
      " - 2s - loss: 1.4457 - acc: 0.4260 - val_loss: 1.4615 - val_acc: 0.4293\n",
      "Epoch 42/300\n",
      " - 1s - loss: 1.4407 - acc: 0.4264 - val_loss: 1.4505 - val_acc: 0.4283\n",
      "Epoch 43/300\n",
      " - 2s - loss: 1.4291 - acc: 0.4326 - val_loss: 1.5078 - val_acc: 0.4053\n",
      "Epoch 44/300\n",
      " - 2s - loss: 1.4319 - acc: 0.4304 - val_loss: 1.4519 - val_acc: 0.4317\n",
      "Epoch 45/300\n",
      " - 1s - loss: 1.4269 - acc: 0.4337 - val_loss: 1.4685 - val_acc: 0.4102\n",
      "Epoch 46/300\n",
      " - 1s - loss: 1.4254 - acc: 0.4364 - val_loss: 1.4529 - val_acc: 0.4278\n",
      "Epoch 47/300\n",
      " - 1s - loss: 1.4184 - acc: 0.4342 - val_loss: 1.4697 - val_acc: 0.4151\n",
      "Epoch 48/300\n",
      " - 1s - loss: 1.4246 - acc: 0.4364 - val_loss: 1.4659 - val_acc: 0.4107\n",
      "Epoch 49/300\n",
      " - 2s - loss: 1.4211 - acc: 0.4325 - val_loss: 1.4435 - val_acc: 0.4312\n",
      "Epoch 50/300\n",
      " - 1s - loss: 1.4103 - acc: 0.4399 - val_loss: 1.4490 - val_acc: 0.4386\n",
      "Epoch 51/300\n",
      " - 1s - loss: 1.4102 - acc: 0.4400 - val_loss: 1.4366 - val_acc: 0.4356\n",
      "Epoch 52/300\n",
      " - 1s - loss: 1.4036 - acc: 0.4430 - val_loss: 1.4465 - val_acc: 0.4298\n",
      "Epoch 53/300\n",
      " - 1s - loss: 1.4107 - acc: 0.4455 - val_loss: 1.4557 - val_acc: 0.4254\n",
      "Epoch 54/300\n",
      " - 1s - loss: 1.4030 - acc: 0.4455 - val_loss: 1.4663 - val_acc: 0.4185\n",
      "Epoch 55/300\n",
      " - 2s - loss: 1.3945 - acc: 0.4493 - val_loss: 1.4516 - val_acc: 0.4219\n",
      "Epoch 56/300\n",
      " - 1s - loss: 1.3923 - acc: 0.4490 - val_loss: 1.4377 - val_acc: 0.4312\n",
      "Epoch 57/300\n",
      " - 1s - loss: 1.3989 - acc: 0.4492 - val_loss: 1.4300 - val_acc: 0.4395\n",
      "Epoch 58/300\n",
      " - 1s - loss: 1.3894 - acc: 0.4431 - val_loss: 1.4288 - val_acc: 0.4322\n",
      "Epoch 59/300\n",
      " - 2s - loss: 1.3875 - acc: 0.4492 - val_loss: 1.4279 - val_acc: 0.4361\n",
      "Epoch 60/300\n",
      " - 1s - loss: 1.3844 - acc: 0.4535 - val_loss: 1.4308 - val_acc: 0.4400\n",
      "Epoch 61/300\n",
      " - 1s - loss: 1.3830 - acc: 0.4520 - val_loss: 1.4333 - val_acc: 0.4430\n",
      "Epoch 62/300\n",
      " - 2s - loss: 1.3743 - acc: 0.4547 - val_loss: 1.4544 - val_acc: 0.4278\n",
      "Epoch 63/300\n",
      " - 2s - loss: 1.3763 - acc: 0.4547 - val_loss: 1.4159 - val_acc: 0.4469\n",
      "Epoch 64/300\n",
      " - 1s - loss: 1.3711 - acc: 0.4578 - val_loss: 1.4175 - val_acc: 0.4449\n",
      "Epoch 65/300\n",
      " - 2s - loss: 1.3860 - acc: 0.4528 - val_loss: 1.4383 - val_acc: 0.4332\n",
      "Epoch 66/300\n",
      " - 1s - loss: 1.3688 - acc: 0.4544 - val_loss: 1.4367 - val_acc: 0.4391\n",
      "Epoch 67/300\n",
      " - 1s - loss: 1.3651 - acc: 0.4567 - val_loss: 1.4253 - val_acc: 0.4508\n",
      "Epoch 68/300\n",
      " - 1s - loss: 1.3684 - acc: 0.4574 - val_loss: 1.4525 - val_acc: 0.4317\n",
      "Epoch 69/300\n",
      " - 1s - loss: 1.3610 - acc: 0.4638 - val_loss: 1.4171 - val_acc: 0.4484\n",
      "Epoch 70/300\n",
      " - 1s - loss: 1.3632 - acc: 0.4601 - val_loss: 1.4175 - val_acc: 0.4415\n",
      "Epoch 71/300\n",
      " - 1s - loss: 1.3579 - acc: 0.4608 - val_loss: 1.4385 - val_acc: 0.4347\n",
      "Epoch 72/300\n",
      " - 2s - loss: 1.3620 - acc: 0.4643 - val_loss: 1.4297 - val_acc: 0.4356\n",
      "Epoch 73/300\n",
      " - 2s - loss: 1.3535 - acc: 0.4634 - val_loss: 1.4479 - val_acc: 0.4327\n",
      "Epoch 74/300\n",
      " - 1s - loss: 1.3472 - acc: 0.4661 - val_loss: 1.4082 - val_acc: 0.4542\n",
      "Epoch 75/300\n",
      " - 1s - loss: 1.3479 - acc: 0.4643 - val_loss: 1.4203 - val_acc: 0.4347\n",
      "Epoch 76/300\n",
      " - 1s - loss: 1.3476 - acc: 0.4655 - val_loss: 1.4144 - val_acc: 0.4376\n",
      "Epoch 77/300\n",
      " - 2s - loss: 1.3439 - acc: 0.4684 - val_loss: 1.4132 - val_acc: 0.4562\n",
      "Epoch 78/300\n",
      " - 2s - loss: 1.3465 - acc: 0.4620 - val_loss: 1.4216 - val_acc: 0.4254\n",
      "Epoch 79/300\n",
      " - 2s - loss: 1.3410 - acc: 0.4701 - val_loss: 1.4194 - val_acc: 0.4533\n",
      "Epoch 80/300\n",
      " - 1s - loss: 1.3381 - acc: 0.4682 - val_loss: 1.4134 - val_acc: 0.4484\n",
      "Epoch 81/300\n",
      " - 1s - loss: 1.3352 - acc: 0.4678 - val_loss: 1.4525 - val_acc: 0.4161\n",
      "Epoch 82/300\n",
      " - 2s - loss: 1.3421 - acc: 0.4684 - val_loss: 1.4028 - val_acc: 0.4674\n",
      "Epoch 83/300\n",
      " - 1s - loss: 1.3346 - acc: 0.4708 - val_loss: 1.4081 - val_acc: 0.4533\n",
      "Epoch 84/300\n",
      " - 1s - loss: 1.3339 - acc: 0.4695 - val_loss: 1.4167 - val_acc: 0.4391\n",
      "Epoch 85/300\n",
      " - 2s - loss: 1.3239 - acc: 0.4770 - val_loss: 1.3942 - val_acc: 0.4572\n",
      "Epoch 86/300\n",
      " - 2s - loss: 1.3286 - acc: 0.4713 - val_loss: 1.4030 - val_acc: 0.4533\n",
      "Epoch 87/300\n",
      " - 2s - loss: 1.3256 - acc: 0.4768 - val_loss: 1.4224 - val_acc: 0.4435\n",
      "Epoch 88/300\n",
      " - 2s - loss: 1.3199 - acc: 0.4730 - val_loss: 1.4106 - val_acc: 0.4459\n",
      "Epoch 89/300\n",
      " - 2s - loss: 1.3242 - acc: 0.4726 - val_loss: 1.4081 - val_acc: 0.4464\n",
      "Epoch 90/300\n",
      " - 2s - loss: 1.3230 - acc: 0.4706 - val_loss: 1.4177 - val_acc: 0.4547\n",
      "Epoch 91/300\n",
      " - 2s - loss: 1.3178 - acc: 0.4751 - val_loss: 1.3973 - val_acc: 0.4474\n",
      "Epoch 92/300\n",
      " - 2s - loss: 1.3134 - acc: 0.4783 - val_loss: 1.4320 - val_acc: 0.4347\n",
      "3-dense-64-nodes-0.001-learning_rate-64-batch_size-1554675495\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 1s - loss: 1.9575 - acc: 0.2500 - val_loss: 1.7094 - val_acc: 0.3201\n",
      "Epoch 2/300\n",
      " - 1s - loss: 1.7232 - acc: 0.3179 - val_loss: 1.7108 - val_acc: 0.3226\n",
      "Epoch 3/300\n",
      " - 1s - loss: 1.6922 - acc: 0.3271 - val_loss: 1.6499 - val_acc: 0.3314\n",
      "Epoch 4/300\n",
      " - 1s - loss: 1.6610 - acc: 0.3447 - val_loss: 1.6292 - val_acc: 0.3421\n",
      "Epoch 5/300\n",
      " - 1s - loss: 1.6401 - acc: 0.3531 - val_loss: 1.6066 - val_acc: 0.3598\n",
      "Epoch 6/300\n",
      " - 1s - loss: 1.6241 - acc: 0.3589 - val_loss: 1.6186 - val_acc: 0.3603\n",
      "Epoch 7/300\n",
      " - 1s - loss: 1.6109 - acc: 0.3649 - val_loss: 1.5851 - val_acc: 0.3651\n",
      "Epoch 8/300\n",
      " - 1s - loss: 1.6045 - acc: 0.3624 - val_loss: 1.5912 - val_acc: 0.3647\n",
      "Epoch 9/300\n",
      " - 1s - loss: 1.5937 - acc: 0.3708 - val_loss: 1.5751 - val_acc: 0.3779\n",
      "Epoch 10/300\n",
      " - 1s - loss: 1.5901 - acc: 0.3698 - val_loss: 1.5816 - val_acc: 0.3563\n",
      "Epoch 11/300\n",
      " - 1s - loss: 1.5808 - acc: 0.3770 - val_loss: 1.5636 - val_acc: 0.3774\n",
      "Epoch 12/300\n",
      " - 1s - loss: 1.5810 - acc: 0.3724 - val_loss: 1.5504 - val_acc: 0.3847\n",
      "Epoch 13/300\n",
      " - 1s - loss: 1.5729 - acc: 0.3765 - val_loss: 1.5622 - val_acc: 0.3793\n",
      "Epoch 14/300\n",
      " - 1s - loss: 1.5649 - acc: 0.3776 - val_loss: 1.5477 - val_acc: 0.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/300\n",
      " - 1s - loss: 1.5586 - acc: 0.3803 - val_loss: 1.5766 - val_acc: 0.3818\n",
      "Epoch 16/300\n",
      " - 1s - loss: 1.5575 - acc: 0.3792 - val_loss: 1.5459 - val_acc: 0.3882\n",
      "Epoch 17/300\n",
      " - 1s - loss: 1.5520 - acc: 0.3813 - val_loss: 1.5324 - val_acc: 0.3930\n",
      "Epoch 18/300\n",
      " - 1s - loss: 1.5512 - acc: 0.3868 - val_loss: 1.5331 - val_acc: 0.3970\n",
      "Epoch 19/300\n",
      " - 1s - loss: 1.5479 - acc: 0.3873 - val_loss: 1.5318 - val_acc: 0.3950\n",
      "Epoch 20/300\n",
      " - 1s - loss: 1.5420 - acc: 0.3887 - val_loss: 1.5216 - val_acc: 0.3945\n",
      "Epoch 21/300\n",
      " - 1s - loss: 1.5363 - acc: 0.3923 - val_loss: 1.5325 - val_acc: 0.3989\n",
      "Epoch 22/300\n",
      " - 1s - loss: 1.5324 - acc: 0.3928 - val_loss: 1.5355 - val_acc: 0.4009\n",
      "Epoch 23/300\n",
      " - 1s - loss: 1.5275 - acc: 0.3954 - val_loss: 1.5244 - val_acc: 0.3945\n",
      "Epoch 24/300\n",
      " - 1s - loss: 1.5271 - acc: 0.3948 - val_loss: 1.5407 - val_acc: 0.3960\n",
      "Epoch 25/300\n",
      " - 1s - loss: 1.5312 - acc: 0.3950 - val_loss: 1.5086 - val_acc: 0.4072\n",
      "Epoch 26/300\n",
      " - 1s - loss: 1.5235 - acc: 0.3961 - val_loss: 1.5095 - val_acc: 0.4068\n",
      "Epoch 27/300\n",
      " - 1s - loss: 1.5160 - acc: 0.3978 - val_loss: 1.5070 - val_acc: 0.4014\n",
      "Epoch 28/300\n",
      " - 1s - loss: 1.5127 - acc: 0.4007 - val_loss: 1.4996 - val_acc: 0.4063\n",
      "Epoch 29/300\n",
      " - 1s - loss: 1.5109 - acc: 0.4022 - val_loss: 1.5052 - val_acc: 0.4058\n",
      "Epoch 30/300\n",
      " - 1s - loss: 1.5057 - acc: 0.4036 - val_loss: 1.5350 - val_acc: 0.3852\n",
      "Epoch 31/300\n",
      " - 1s - loss: 1.5019 - acc: 0.4053 - val_loss: 1.5080 - val_acc: 0.4126\n",
      "Epoch 32/300\n",
      " - 1s - loss: 1.5007 - acc: 0.4087 - val_loss: 1.5043 - val_acc: 0.4107\n",
      "Epoch 33/300\n",
      " - 1s - loss: 1.4954 - acc: 0.4106 - val_loss: 1.5137 - val_acc: 0.4082\n",
      "Epoch 34/300\n",
      " - 1s - loss: 1.5030 - acc: 0.4057 - val_loss: 1.5504 - val_acc: 0.3882\n",
      "Epoch 35/300\n",
      " - 1s - loss: 1.4941 - acc: 0.4095 - val_loss: 1.4844 - val_acc: 0.4205\n",
      "Epoch 36/300\n",
      " - 1s - loss: 1.4870 - acc: 0.4123 - val_loss: 1.5101 - val_acc: 0.4058\n",
      "Epoch 37/300\n",
      " - 1s - loss: 1.4882 - acc: 0.4121 - val_loss: 1.4882 - val_acc: 0.4131\n",
      "Epoch 38/300\n",
      " - 1s - loss: 1.4847 - acc: 0.4164 - val_loss: 1.4922 - val_acc: 0.4043\n",
      "Epoch 39/300\n",
      " - 1s - loss: 1.4840 - acc: 0.4123 - val_loss: 1.4975 - val_acc: 0.4209\n",
      "Epoch 40/300\n",
      " - 1s - loss: 1.4749 - acc: 0.4136 - val_loss: 1.4754 - val_acc: 0.4200\n",
      "Epoch 41/300\n",
      " - 1s - loss: 1.4711 - acc: 0.4177 - val_loss: 1.4674 - val_acc: 0.4263\n",
      "Epoch 42/300\n",
      " - 1s - loss: 1.4772 - acc: 0.4151 - val_loss: 1.5144 - val_acc: 0.4063\n",
      "Epoch 43/300\n",
      " - 1s - loss: 1.4705 - acc: 0.4192 - val_loss: 1.4808 - val_acc: 0.4112\n",
      "Epoch 44/300\n",
      " - 1s - loss: 1.4641 - acc: 0.4197 - val_loss: 1.4906 - val_acc: 0.4009\n",
      "Epoch 45/300\n",
      " - 1s - loss: 1.4634 - acc: 0.4219 - val_loss: 1.4797 - val_acc: 0.4053\n",
      "Epoch 46/300\n",
      " - 1s - loss: 1.4628 - acc: 0.4207 - val_loss: 1.4924 - val_acc: 0.4107\n",
      "Epoch 47/300\n",
      " - 1s - loss: 1.4544 - acc: 0.4242 - val_loss: 1.4579 - val_acc: 0.4234\n",
      "Epoch 48/300\n",
      " - 1s - loss: 1.4558 - acc: 0.4254 - val_loss: 1.4689 - val_acc: 0.4190\n",
      "Epoch 49/300\n",
      " - 1s - loss: 1.4616 - acc: 0.4180 - val_loss: 1.4533 - val_acc: 0.4298\n",
      "Epoch 50/300\n",
      " - 1s - loss: 1.4526 - acc: 0.4241 - val_loss: 1.4798 - val_acc: 0.4156\n",
      "Epoch 51/300\n",
      " - 1s - loss: 1.4465 - acc: 0.4273 - val_loss: 1.4712 - val_acc: 0.4219\n",
      "Epoch 52/300\n",
      " - 1s - loss: 1.4457 - acc: 0.4307 - val_loss: 1.5171 - val_acc: 0.4077\n",
      "Epoch 53/300\n",
      " - 1s - loss: 1.4442 - acc: 0.4300 - val_loss: 1.4578 - val_acc: 0.4205\n",
      "Epoch 54/300\n",
      " - 1s - loss: 1.4433 - acc: 0.4289 - val_loss: 1.4561 - val_acc: 0.4229\n",
      "Epoch 55/300\n",
      " - 1s - loss: 1.4400 - acc: 0.4281 - val_loss: 1.4641 - val_acc: 0.4332\n",
      "Epoch 56/300\n",
      " - 1s - loss: 1.4373 - acc: 0.4371 - val_loss: 1.4545 - val_acc: 0.4327\n",
      "Epoch 57/300\n",
      " - 1s - loss: 1.4392 - acc: 0.4289 - val_loss: 1.4646 - val_acc: 0.4254\n",
      "Epoch 58/300\n",
      " - 1s - loss: 1.4312 - acc: 0.4392 - val_loss: 1.4448 - val_acc: 0.4366\n",
      "Epoch 59/300\n",
      " - 1s - loss: 1.4307 - acc: 0.4343 - val_loss: 1.4984 - val_acc: 0.4263\n",
      "Epoch 60/300\n",
      " - 1s - loss: 1.4297 - acc: 0.4375 - val_loss: 1.4429 - val_acc: 0.4337\n",
      "Epoch 61/300\n",
      " - 1s - loss: 1.4291 - acc: 0.4367 - val_loss: 1.4440 - val_acc: 0.4542\n",
      "Epoch 62/300\n",
      " - 1s - loss: 1.4286 - acc: 0.4298 - val_loss: 1.4377 - val_acc: 0.4356\n",
      "Epoch 63/300\n",
      " - 1s - loss: 1.4236 - acc: 0.4389 - val_loss: 1.4365 - val_acc: 0.4410\n",
      "Epoch 64/300\n",
      " - 1s - loss: 1.4263 - acc: 0.4375 - val_loss: 1.4399 - val_acc: 0.4337\n",
      "Epoch 65/300\n",
      " - 1s - loss: 1.4250 - acc: 0.4385 - val_loss: 1.4453 - val_acc: 0.4366\n",
      "Epoch 66/300\n",
      " - 1s - loss: 1.4219 - acc: 0.4360 - val_loss: 1.4561 - val_acc: 0.4351\n",
      "Epoch 67/300\n",
      " - 1s - loss: 1.4240 - acc: 0.4372 - val_loss: 1.4370 - val_acc: 0.4342\n",
      "Epoch 68/300\n",
      " - 1s - loss: 1.4139 - acc: 0.4458 - val_loss: 1.4535 - val_acc: 0.4361\n",
      "Epoch 69/300\n",
      " - 1s - loss: 1.4076 - acc: 0.4429 - val_loss: 1.4851 - val_acc: 0.4121\n",
      "Epoch 70/300\n",
      " - 1s - loss: 1.4097 - acc: 0.4459 - val_loss: 1.4600 - val_acc: 0.4254\n",
      "Epoch 71/300\n",
      " - 1s - loss: 1.4064 - acc: 0.4447 - val_loss: 1.4480 - val_acc: 0.4337\n",
      "3-dense-64-nodes-0.001-learning_rate-128-batch_size-1554675559\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,546\n",
      "Trainable params: 9,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 1s - loss: 2.0334 - acc: 0.2304 - val_loss: 1.7838 - val_acc: 0.3005\n",
      "Epoch 2/300\n",
      " - 0s - loss: 1.7678 - acc: 0.3024 - val_loss: 1.7254 - val_acc: 0.3049\n",
      "Epoch 3/300\n",
      " - 1s - loss: 1.7273 - acc: 0.3176 - val_loss: 1.6781 - val_acc: 0.3231\n",
      "Epoch 4/300\n",
      " - 1s - loss: 1.6999 - acc: 0.3327 - val_loss: 1.6757 - val_acc: 0.3372\n",
      "Epoch 5/300\n",
      " - 0s - loss: 1.6882 - acc: 0.3302 - val_loss: 1.6408 - val_acc: 0.3407\n",
      "Epoch 6/300\n",
      " - 0s - loss: 1.6652 - acc: 0.3420 - val_loss: 1.6274 - val_acc: 0.3441\n",
      "Epoch 7/300\n",
      " - 1s - loss: 1.6526 - acc: 0.3491 - val_loss: 1.6225 - val_acc: 0.3470\n",
      "Epoch 8/300\n",
      " - 1s - loss: 1.6405 - acc: 0.3561 - val_loss: 1.6192 - val_acc: 0.3549\n",
      "Epoch 9/300\n",
      " - 0s - loss: 1.6355 - acc: 0.3534 - val_loss: 1.6005 - val_acc: 0.3651\n",
      "Epoch 10/300\n",
      " - 1s - loss: 1.6240 - acc: 0.3594 - val_loss: 1.5975 - val_acc: 0.3681\n",
      "Epoch 11/300\n",
      " - 1s - loss: 1.6118 - acc: 0.3641 - val_loss: 1.5942 - val_acc: 0.3598\n",
      "Epoch 12/300\n",
      " - 1s - loss: 1.6165 - acc: 0.3600 - val_loss: 1.5988 - val_acc: 0.3744\n",
      "Epoch 13/300\n",
      " - 0s - loss: 1.6045 - acc: 0.3686 - val_loss: 1.5798 - val_acc: 0.3710\n",
      "Epoch 14/300\n",
      " - 0s - loss: 1.5973 - acc: 0.3711 - val_loss: 1.5837 - val_acc: 0.3632\n",
      "Epoch 15/300\n",
      " - 0s - loss: 1.5917 - acc: 0.3710 - val_loss: 1.5678 - val_acc: 0.3779\n",
      "Epoch 16/300\n",
      " - 0s - loss: 1.5877 - acc: 0.3763 - val_loss: 1.5691 - val_acc: 0.3842\n",
      "Epoch 17/300\n",
      " - 0s - loss: 1.5838 - acc: 0.3741 - val_loss: 1.5617 - val_acc: 0.3774\n",
      "Epoch 18/300\n",
      " - 1s - loss: 1.5820 - acc: 0.3778 - val_loss: 1.5547 - val_acc: 0.3842\n",
      "Epoch 19/300\n",
      " - 0s - loss: 1.5785 - acc: 0.3798 - val_loss: 1.5638 - val_acc: 0.3754\n",
      "Epoch 20/300\n",
      " - 1s - loss: 1.5806 - acc: 0.3731 - val_loss: 1.5607 - val_acc: 0.3793\n",
      "Epoch 21/300\n",
      " - 1s - loss: 1.5702 - acc: 0.3791 - val_loss: 1.5828 - val_acc: 0.3681\n",
      "Epoch 22/300\n",
      " - 1s - loss: 1.5712 - acc: 0.3768 - val_loss: 1.5516 - val_acc: 0.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/300\n",
      " - 1s - loss: 1.5652 - acc: 0.3814 - val_loss: 1.5456 - val_acc: 0.3798\n",
      "Epoch 24/300\n",
      " - 1s - loss: 1.5657 - acc: 0.3865 - val_loss: 1.5497 - val_acc: 0.3842\n",
      "Epoch 25/300\n",
      " - 1s - loss: 1.5582 - acc: 0.3867 - val_loss: 1.5566 - val_acc: 0.3808\n",
      "Epoch 26/300\n",
      " - 1s - loss: 1.5591 - acc: 0.3850 - val_loss: 1.5589 - val_acc: 0.3784\n",
      "Epoch 27/300\n",
      " - 1s - loss: 1.5534 - acc: 0.3927 - val_loss: 1.5405 - val_acc: 0.3901\n",
      "Epoch 28/300\n",
      " - 1s - loss: 1.5530 - acc: 0.3888 - val_loss: 1.5396 - val_acc: 0.3901\n",
      "Epoch 29/300\n",
      " - 1s - loss: 1.5522 - acc: 0.3895 - val_loss: 1.5465 - val_acc: 0.3867\n",
      "Epoch 30/300\n",
      " - 1s - loss: 1.5461 - acc: 0.3901 - val_loss: 1.5436 - val_acc: 0.3930\n",
      "Epoch 31/300\n",
      " - 0s - loss: 1.5443 - acc: 0.3943 - val_loss: 1.5291 - val_acc: 0.3960\n",
      "Epoch 32/300\n",
      " - 1s - loss: 1.5474 - acc: 0.3910 - val_loss: 1.5286 - val_acc: 0.3979\n",
      "Epoch 33/300\n",
      " - 0s - loss: 1.5413 - acc: 0.3939 - val_loss: 1.5663 - val_acc: 0.3857\n",
      "Epoch 34/300\n",
      " - 0s - loss: 1.5445 - acc: 0.3930 - val_loss: 1.5248 - val_acc: 0.3965\n",
      "Epoch 35/300\n",
      " - 1s - loss: 1.5324 - acc: 0.3973 - val_loss: 1.5277 - val_acc: 0.3896\n",
      "Epoch 36/300\n",
      " - 1s - loss: 1.5290 - acc: 0.4012 - val_loss: 1.5213 - val_acc: 0.4004\n",
      "Epoch 37/300\n",
      " - 0s - loss: 1.5345 - acc: 0.3958 - val_loss: 1.5204 - val_acc: 0.3940\n",
      "Epoch 38/300\n",
      " - 0s - loss: 1.5248 - acc: 0.3973 - val_loss: 1.5209 - val_acc: 0.4014\n",
      "Epoch 39/300\n",
      " - 0s - loss: 1.5248 - acc: 0.3971 - val_loss: 1.5232 - val_acc: 0.3994\n",
      "Epoch 40/300\n",
      " - 1s - loss: 1.5232 - acc: 0.3991 - val_loss: 1.5209 - val_acc: 0.3960\n",
      "Epoch 41/300\n",
      " - 1s - loss: 1.5254 - acc: 0.3961 - val_loss: 1.5400 - val_acc: 0.3886\n",
      "Epoch 42/300\n",
      " - 0s - loss: 1.5193 - acc: 0.3980 - val_loss: 1.5059 - val_acc: 0.4068\n",
      "Epoch 43/300\n",
      " - 1s - loss: 1.5152 - acc: 0.4017 - val_loss: 1.5282 - val_acc: 0.4019\n",
      "Epoch 44/300\n",
      " - 0s - loss: 1.5112 - acc: 0.4037 - val_loss: 1.5073 - val_acc: 0.4068\n",
      "Epoch 45/300\n",
      " - 0s - loss: 1.5142 - acc: 0.4035 - val_loss: 1.5298 - val_acc: 0.3896\n",
      "Epoch 46/300\n",
      " - 0s - loss: 1.5138 - acc: 0.4032 - val_loss: 1.5173 - val_acc: 0.3921\n",
      "Epoch 47/300\n",
      " - 1s - loss: 1.5087 - acc: 0.4012 - val_loss: 1.5262 - val_acc: 0.3935\n",
      "Epoch 48/300\n",
      " - 0s - loss: 1.5041 - acc: 0.4052 - val_loss: 1.5096 - val_acc: 0.3984\n",
      "Epoch 49/300\n",
      " - 0s - loss: 1.5078 - acc: 0.4014 - val_loss: 1.5218 - val_acc: 0.4058\n",
      "Epoch 50/300\n",
      " - 0s - loss: 1.4960 - acc: 0.4096 - val_loss: 1.5008 - val_acc: 0.4038\n",
      "Epoch 51/300\n",
      " - 0s - loss: 1.5000 - acc: 0.4043 - val_loss: 1.4960 - val_acc: 0.4102\n",
      "Epoch 52/300\n",
      " - 1s - loss: 1.4988 - acc: 0.4090 - val_loss: 1.5082 - val_acc: 0.3984\n",
      "Epoch 53/300\n",
      " - 0s - loss: 1.4965 - acc: 0.4081 - val_loss: 1.5066 - val_acc: 0.4136\n",
      "Epoch 54/300\n",
      " - 0s - loss: 1.4907 - acc: 0.4083 - val_loss: 1.5077 - val_acc: 0.4058\n",
      "Epoch 55/300\n",
      " - 0s - loss: 1.4935 - acc: 0.4093 - val_loss: 1.4954 - val_acc: 0.4023\n",
      "Epoch 56/300\n",
      " - 0s - loss: 1.4876 - acc: 0.4107 - val_loss: 1.4937 - val_acc: 0.4107\n",
      "Epoch 57/300\n",
      " - 0s - loss: 1.5013 - acc: 0.4058 - val_loss: 1.5005 - val_acc: 0.4043\n",
      "Epoch 58/300\n",
      " - 0s - loss: 1.4870 - acc: 0.4087 - val_loss: 1.4971 - val_acc: 0.4165\n",
      "Epoch 59/300\n",
      " - 0s - loss: 1.4804 - acc: 0.4132 - val_loss: 1.4927 - val_acc: 0.4121\n",
      "Epoch 60/300\n",
      " - 1s - loss: 1.4781 - acc: 0.4137 - val_loss: 1.4995 - val_acc: 0.4126\n",
      "Epoch 61/300\n",
      " - 0s - loss: 1.4781 - acc: 0.4169 - val_loss: 1.5036 - val_acc: 0.4087\n",
      "Epoch 62/300\n",
      " - 0s - loss: 1.4805 - acc: 0.4099 - val_loss: 1.5078 - val_acc: 0.4058\n",
      "Epoch 63/300\n",
      " - 0s - loss: 1.4765 - acc: 0.4158 - val_loss: 1.4893 - val_acc: 0.4141\n",
      "Epoch 64/300\n",
      " - 1s - loss: 1.4751 - acc: 0.4194 - val_loss: 1.4794 - val_acc: 0.4156\n",
      "Epoch 65/300\n",
      " - 0s - loss: 1.4754 - acc: 0.4169 - val_loss: 1.4988 - val_acc: 0.4121\n",
      "Epoch 66/300\n",
      " - 0s - loss: 1.4712 - acc: 0.4207 - val_loss: 1.5113 - val_acc: 0.4087\n",
      "Epoch 67/300\n",
      " - 0s - loss: 1.4722 - acc: 0.4184 - val_loss: 1.4852 - val_acc: 0.4229\n",
      "Epoch 68/300\n",
      " - 0s - loss: 1.4693 - acc: 0.4143 - val_loss: 1.4996 - val_acc: 0.4072\n",
      "Epoch 69/300\n",
      " - 0s - loss: 1.4660 - acc: 0.4213 - val_loss: 1.4797 - val_acc: 0.4229\n",
      "Epoch 70/300\n",
      " - 1s - loss: 1.4641 - acc: 0.4214 - val_loss: 1.4864 - val_acc: 0.4185\n",
      "Epoch 71/300\n",
      " - 0s - loss: 1.4618 - acc: 0.4216 - val_loss: 1.4886 - val_acc: 0.4229\n",
      "Epoch 72/300\n",
      " - 0s - loss: 1.4635 - acc: 0.4180 - val_loss: 1.4899 - val_acc: 0.4254\n",
      "Epoch 73/300\n",
      " - 0s - loss: 1.4622 - acc: 0.4209 - val_loss: 1.4795 - val_acc: 0.4058\n",
      "Epoch 74/300\n",
      " - 0s - loss: 1.4574 - acc: 0.4232 - val_loss: 1.4712 - val_acc: 0.4146\n",
      "Epoch 75/300\n",
      " - 0s - loss: 1.4626 - acc: 0.4230 - val_loss: 1.4743 - val_acc: 0.4229\n",
      "Epoch 76/300\n",
      " - 0s - loss: 1.4551 - acc: 0.4243 - val_loss: 1.4726 - val_acc: 0.4195\n",
      "Epoch 77/300\n",
      " - 0s - loss: 1.4551 - acc: 0.4257 - val_loss: 1.4747 - val_acc: 0.4205\n",
      "Epoch 78/300\n",
      " - 1s - loss: 1.4533 - acc: 0.4251 - val_loss: 1.4764 - val_acc: 0.4258\n",
      "Epoch 79/300\n",
      " - 0s - loss: 1.4530 - acc: 0.4238 - val_loss: 1.4700 - val_acc: 0.4239\n",
      "Epoch 80/300\n",
      " - 0s - loss: 1.4464 - acc: 0.4277 - val_loss: 1.4703 - val_acc: 0.4263\n",
      "Epoch 81/300\n",
      " - 0s - loss: 1.4467 - acc: 0.4259 - val_loss: 1.4855 - val_acc: 0.4239\n",
      "Epoch 82/300\n",
      " - 1s - loss: 1.4581 - acc: 0.4255 - val_loss: 1.5432 - val_acc: 0.3989\n",
      "Epoch 83/300\n",
      " - 1s - loss: 1.4458 - acc: 0.4266 - val_loss: 1.4807 - val_acc: 0.4107\n",
      "Epoch 84/300\n",
      " - 0s - loss: 1.4421 - acc: 0.4286 - val_loss: 1.4838 - val_acc: 0.4141\n",
      "Epoch 85/300\n",
      " - 0s - loss: 1.4429 - acc: 0.4277 - val_loss: 1.4968 - val_acc: 0.4244\n",
      "Epoch 86/300\n",
      " - 0s - loss: 1.4399 - acc: 0.4281 - val_loss: 1.4638 - val_acc: 0.4337\n",
      "Epoch 87/300\n",
      " - 0s - loss: 1.4460 - acc: 0.4248 - val_loss: 1.4683 - val_acc: 0.4302\n",
      "Epoch 88/300\n",
      " - 0s - loss: 1.4526 - acc: 0.4256 - val_loss: 1.4886 - val_acc: 0.4180\n",
      "Epoch 89/300\n",
      " - 0s - loss: 1.4348 - acc: 0.4305 - val_loss: 1.5048 - val_acc: 0.4033\n",
      "Epoch 90/300\n",
      " - 1s - loss: 1.4398 - acc: 0.4320 - val_loss: 1.4960 - val_acc: 0.4131\n",
      "Epoch 91/300\n",
      " - 0s - loss: 1.4378 - acc: 0.4356 - val_loss: 1.4797 - val_acc: 0.4214\n",
      "Epoch 92/300\n",
      " - 0s - loss: 1.4363 - acc: 0.4303 - val_loss: 1.4591 - val_acc: 0.4391\n",
      "Epoch 93/300\n",
      " - 1s - loss: 1.4298 - acc: 0.4360 - val_loss: 1.4569 - val_acc: 0.4254\n",
      "Epoch 94/300\n",
      " - 0s - loss: 1.4287 - acc: 0.4337 - val_loss: 1.4646 - val_acc: 0.4351\n",
      "Epoch 95/300\n",
      " - 0s - loss: 1.4302 - acc: 0.4341 - val_loss: 1.4803 - val_acc: 0.4112\n",
      "Epoch 96/300\n",
      " - 0s - loss: 1.4382 - acc: 0.4314 - val_loss: 1.4689 - val_acc: 0.4239\n",
      "Epoch 97/300\n",
      " - 0s - loss: 1.4323 - acc: 0.4336 - val_loss: 1.4598 - val_acc: 0.4283\n",
      "Epoch 98/300\n",
      " - 0s - loss: 1.4361 - acc: 0.4274 - val_loss: 1.4667 - val_acc: 0.4351\n",
      "Epoch 99/300\n",
      " - 0s - loss: 1.4327 - acc: 0.4312 - val_loss: 1.4860 - val_acc: 0.4175\n",
      "Epoch 100/300\n",
      " - 0s - loss: 1.4297 - acc: 0.4374 - val_loss: 1.4554 - val_acc: 0.4337\n",
      "Epoch 101/300\n",
      " - 0s - loss: 1.4244 - acc: 0.4361 - val_loss: 1.4686 - val_acc: 0.4254\n",
      "Epoch 102/300\n",
      " - 0s - loss: 1.4221 - acc: 0.4405 - val_loss: 1.4655 - val_acc: 0.4254\n",
      "4-dense-64-nodes-0.001-learning_rate-2-batch_size-1554675612\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 25s - loss: 1.7923 - acc: 0.2927 - val_loss: 1.6634 - val_acc: 0.3338\n",
      "Epoch 2/300\n",
      " - 25s - loss: 1.6861 - acc: 0.3285 - val_loss: 1.6812 - val_acc: 0.3265\n",
      "Epoch 3/300\n",
      " - 25s - loss: 1.6484 - acc: 0.3421 - val_loss: 1.6577 - val_acc: 0.3338\n",
      "Epoch 4/300\n",
      " - 22s - loss: 1.6282 - acc: 0.3496 - val_loss: 1.5776 - val_acc: 0.3622\n",
      "Epoch 5/300\n",
      " - 22s - loss: 1.6147 - acc: 0.3588 - val_loss: 1.6905 - val_acc: 0.3275\n",
      "Epoch 6/300\n",
      " - 24s - loss: 1.5979 - acc: 0.3608 - val_loss: 1.6053 - val_acc: 0.3666\n",
      "Epoch 7/300\n",
      " - 22s - loss: 1.5819 - acc: 0.3713 - val_loss: 1.5740 - val_acc: 0.3872\n",
      "Epoch 8/300\n",
      " - 25s - loss: 1.5725 - acc: 0.3735 - val_loss: 1.6249 - val_acc: 0.3456\n",
      "Epoch 9/300\n",
      " - 22s - loss: 1.5634 - acc: 0.3750 - val_loss: 1.5290 - val_acc: 0.3847\n",
      "Epoch 10/300\n",
      " - 22s - loss: 1.5548 - acc: 0.3797 - val_loss: 1.5474 - val_acc: 0.3862\n",
      "Epoch 11/300\n",
      " - 21s - loss: 1.5504 - acc: 0.3830 - val_loss: 1.5951 - val_acc: 0.3744\n",
      "Epoch 12/300\n",
      " - 22s - loss: 1.5385 - acc: 0.3863 - val_loss: 1.5865 - val_acc: 0.3676\n",
      "Epoch 13/300\n",
      " - 22s - loss: 1.5365 - acc: 0.3911 - val_loss: 1.5037 - val_acc: 0.4146\n",
      "Epoch 14/300\n",
      " - 21s - loss: 1.5285 - acc: 0.3972 - val_loss: 1.5161 - val_acc: 0.4023\n",
      "Epoch 15/300\n",
      " - 22s - loss: 1.5205 - acc: 0.3966 - val_loss: 1.5565 - val_acc: 0.4048\n",
      "Epoch 16/300\n",
      " - 25s - loss: 1.5187 - acc: 0.3981 - val_loss: 1.4889 - val_acc: 0.4234\n",
      "Epoch 17/300\n",
      " - 24s - loss: 1.5129 - acc: 0.3975 - val_loss: 1.5144 - val_acc: 0.3960\n",
      "Epoch 18/300\n",
      " - 26s - loss: 1.5066 - acc: 0.3994 - val_loss: 1.4790 - val_acc: 0.4156\n",
      "Epoch 19/300\n",
      " - 25s - loss: 1.5013 - acc: 0.4058 - val_loss: 1.4861 - val_acc: 0.4273\n",
      "Epoch 20/300\n",
      " - 22s - loss: 1.4936 - acc: 0.4106 - val_loss: 1.5128 - val_acc: 0.4048\n",
      "Epoch 21/300\n",
      " - 25s - loss: 1.4904 - acc: 0.4090 - val_loss: 1.5071 - val_acc: 0.4126\n",
      "Epoch 22/300\n",
      " - 24s - loss: 1.4919 - acc: 0.4066 - val_loss: 1.5167 - val_acc: 0.4092\n",
      "Epoch 23/300\n",
      " - 23s - loss: 1.4844 - acc: 0.4071 - val_loss: 1.5244 - val_acc: 0.4072\n",
      "Epoch 24/300\n",
      " - 23s - loss: 1.4781 - acc: 0.4099 - val_loss: 1.4956 - val_acc: 0.4224\n",
      "Epoch 25/300\n",
      " - 24s - loss: 1.4760 - acc: 0.4139 - val_loss: 1.4764 - val_acc: 0.4278\n",
      "Epoch 26/300\n",
      " - 25s - loss: 1.4694 - acc: 0.4141 - val_loss: 1.4912 - val_acc: 0.4351\n",
      "Epoch 27/300\n",
      " - 25s - loss: 1.4710 - acc: 0.4143 - val_loss: 1.4828 - val_acc: 0.4351\n",
      "Epoch 28/300\n",
      " - 25s - loss: 1.4661 - acc: 0.4176 - val_loss: 1.5294 - val_acc: 0.4063\n",
      "Epoch 29/300\n",
      " - 23s - loss: 1.4622 - acc: 0.4214 - val_loss: 1.5492 - val_acc: 0.4028\n",
      "Epoch 30/300\n",
      " - 26s - loss: 1.4581 - acc: 0.4185 - val_loss: 1.4721 - val_acc: 0.4351\n",
      "Epoch 31/300\n",
      " - 26s - loss: 1.4577 - acc: 0.4177 - val_loss: 1.4721 - val_acc: 0.4288\n",
      "Epoch 32/300\n",
      " - 23s - loss: 1.4568 - acc: 0.4219 - val_loss: 1.5132 - val_acc: 0.4141\n",
      "Epoch 33/300\n",
      " - 24s - loss: 1.4556 - acc: 0.4199 - val_loss: 1.4788 - val_acc: 0.4327\n",
      "Epoch 34/300\n",
      " - 22s - loss: 1.4514 - acc: 0.4227 - val_loss: 1.4814 - val_acc: 0.4219\n",
      "Epoch 35/300\n",
      " - 22s - loss: 1.4472 - acc: 0.4245 - val_loss: 1.4940 - val_acc: 0.4263\n",
      "Epoch 36/300\n",
      " - 23s - loss: 1.4467 - acc: 0.4255 - val_loss: 1.4687 - val_acc: 0.4278\n",
      "4-dense-64-nodes-0.001-learning_rate-4-batch_size-1554676460\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 16s - loss: 1.7866 - acc: 0.2918 - val_loss: 1.6518 - val_acc: 0.3333\n",
      "Epoch 2/300\n",
      " - 14s - loss: 1.6744 - acc: 0.3373 - val_loss: 1.6272 - val_acc: 0.3686\n",
      "Epoch 3/300\n",
      " - 13s - loss: 1.6445 - acc: 0.3449 - val_loss: 1.5867 - val_acc: 0.3612\n",
      "Epoch 4/300\n",
      " - 11s - loss: 1.6241 - acc: 0.3574 - val_loss: 1.6371 - val_acc: 0.3279\n",
      "Epoch 5/300\n",
      " - 11s - loss: 1.6146 - acc: 0.3561 - val_loss: 1.7006 - val_acc: 0.3177\n",
      "Epoch 6/300\n",
      " - 14s - loss: 1.5980 - acc: 0.3655 - val_loss: 1.5630 - val_acc: 0.3759\n",
      "Epoch 7/300\n",
      " - 13s - loss: 1.5850 - acc: 0.3683 - val_loss: 1.5546 - val_acc: 0.3823\n",
      "Epoch 8/300\n",
      " - 11s - loss: 1.5841 - acc: 0.3671 - val_loss: 1.5438 - val_acc: 0.3837\n",
      "Epoch 9/300\n",
      " - 11s - loss: 1.5690 - acc: 0.3765 - val_loss: 1.5766 - val_acc: 0.3828\n",
      "Epoch 10/300\n",
      " - 11s - loss: 1.5634 - acc: 0.3690 - val_loss: 1.5521 - val_acc: 0.3965\n",
      "Epoch 11/300\n",
      " - 11s - loss: 1.5576 - acc: 0.3816 - val_loss: 1.5734 - val_acc: 0.3754\n",
      "Epoch 12/300\n",
      " - 11s - loss: 1.5482 - acc: 0.3825 - val_loss: 1.5355 - val_acc: 0.3823\n",
      "Epoch 13/300\n",
      " - 11s - loss: 1.5454 - acc: 0.3834 - val_loss: 1.6038 - val_acc: 0.3666\n",
      "Epoch 14/300\n",
      " - 14s - loss: 1.5382 - acc: 0.3836 - val_loss: 1.5236 - val_acc: 0.3896\n",
      "Epoch 15/300\n",
      " - 12s - loss: 1.5298 - acc: 0.3908 - val_loss: 1.5065 - val_acc: 0.4165\n",
      "Epoch 16/300\n",
      " - 12s - loss: 1.5255 - acc: 0.3945 - val_loss: 1.5061 - val_acc: 0.4224\n",
      "Epoch 17/300\n",
      " - 11s - loss: 1.5159 - acc: 0.3995 - val_loss: 1.5350 - val_acc: 0.3886\n",
      "Epoch 18/300\n",
      " - 11s - loss: 1.5092 - acc: 0.3964 - val_loss: 1.5279 - val_acc: 0.4087\n",
      "Epoch 19/300\n",
      " - 11s - loss: 1.5022 - acc: 0.4049 - val_loss: 1.5373 - val_acc: 0.3970\n",
      "Epoch 20/300\n",
      " - 11s - loss: 1.4947 - acc: 0.4081 - val_loss: 1.4994 - val_acc: 0.4028\n",
      "Epoch 21/300\n",
      " - 11s - loss: 1.4859 - acc: 0.4039 - val_loss: 1.5062 - val_acc: 0.4072\n",
      "Epoch 22/300\n",
      " - 11s - loss: 1.4847 - acc: 0.4047 - val_loss: 1.4914 - val_acc: 0.3935\n",
      "Epoch 23/300\n",
      " - 11s - loss: 1.4742 - acc: 0.4112 - val_loss: 1.5139 - val_acc: 0.4156\n",
      "Epoch 24/300\n",
      " - 12s - loss: 1.4696 - acc: 0.4090 - val_loss: 1.5433 - val_acc: 0.3813\n",
      "Epoch 25/300\n",
      " - 12s - loss: 1.4656 - acc: 0.4115 - val_loss: 1.4723 - val_acc: 0.4004\n",
      "Epoch 26/300\n",
      " - 13s - loss: 1.4544 - acc: 0.4190 - val_loss: 1.4851 - val_acc: 0.4190\n",
      "4-dense-64-nodes-0.001-learning_rate-8-batch_size-1554676769\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 7s - loss: 1.8015 - acc: 0.2884 - val_loss: 1.6907 - val_acc: 0.3206\n",
      "Epoch 2/300\n",
      " - 6s - loss: 1.6818 - acc: 0.3356 - val_loss: 1.6206 - val_acc: 0.3510\n",
      "Epoch 3/300\n",
      " - 6s - loss: 1.6472 - acc: 0.3470 - val_loss: 1.5818 - val_acc: 0.3779\n",
      "Epoch 4/300\n",
      " - 6s - loss: 1.6288 - acc: 0.3509 - val_loss: 1.5708 - val_acc: 0.3764\n",
      "Epoch 5/300\n",
      " - 7s - loss: 1.6110 - acc: 0.3576 - val_loss: 1.5745 - val_acc: 0.3705\n",
      "Epoch 6/300\n",
      " - 7s - loss: 1.5964 - acc: 0.3671 - val_loss: 1.5598 - val_acc: 0.3867\n",
      "Epoch 7/300\n",
      " - 6s - loss: 1.5878 - acc: 0.3633 - val_loss: 1.5522 - val_acc: 0.3784\n",
      "Epoch 8/300\n",
      " - 6s - loss: 1.5692 - acc: 0.3743 - val_loss: 1.5762 - val_acc: 0.3666\n",
      "Epoch 9/300\n",
      " - 7s - loss: 1.5610 - acc: 0.3767 - val_loss: 1.5282 - val_acc: 0.3906\n",
      "Epoch 10/300\n",
      " - 6s - loss: 1.5504 - acc: 0.3852 - val_loss: 1.5224 - val_acc: 0.3975\n",
      "Epoch 11/300\n",
      " - 7s - loss: 1.5399 - acc: 0.3872 - val_loss: 1.5309 - val_acc: 0.3896\n",
      "Epoch 12/300\n",
      " - 7s - loss: 1.5309 - acc: 0.3832 - val_loss: 1.5409 - val_acc: 0.3896\n",
      "Epoch 13/300\n",
      " - 6s - loss: 1.5240 - acc: 0.3919 - val_loss: 1.5212 - val_acc: 0.3955\n",
      "Epoch 14/300\n",
      " - 6s - loss: 1.5110 - acc: 0.3954 - val_loss: 1.4976 - val_acc: 0.3950\n",
      "Epoch 15/300\n",
      " - 6s - loss: 1.5019 - acc: 0.4027 - val_loss: 1.5279 - val_acc: 0.3940\n",
      "Epoch 16/300\n",
      " - 6s - loss: 1.4946 - acc: 0.4035 - val_loss: 1.4767 - val_acc: 0.4234\n",
      "Epoch 17/300\n",
      " - 6s - loss: 1.4839 - acc: 0.4069 - val_loss: 1.4831 - val_acc: 0.4190\n",
      "Epoch 18/300\n",
      " - 6s - loss: 1.4750 - acc: 0.4094 - val_loss: 1.4726 - val_acc: 0.4097\n",
      "Epoch 19/300\n",
      " - 7s - loss: 1.4681 - acc: 0.4146 - val_loss: 1.4751 - val_acc: 0.4063\n",
      "Epoch 20/300\n",
      " - 6s - loss: 1.4670 - acc: 0.4092 - val_loss: 1.4666 - val_acc: 0.4014\n",
      "Epoch 21/300\n",
      " - 5s - loss: 1.4604 - acc: 0.4146 - val_loss: 1.4436 - val_acc: 0.4205\n",
      "Epoch 22/300\n",
      " - 5s - loss: 1.4487 - acc: 0.4193 - val_loss: 1.4804 - val_acc: 0.4019\n",
      "Epoch 23/300\n",
      " - 5s - loss: 1.4448 - acc: 0.4249 - val_loss: 1.4856 - val_acc: 0.3984\n",
      "Epoch 24/300\n",
      " - 6s - loss: 1.4388 - acc: 0.4210 - val_loss: 1.4933 - val_acc: 0.4023\n",
      "Epoch 25/300\n",
      " - 7s - loss: 1.4325 - acc: 0.4295 - val_loss: 1.4170 - val_acc: 0.4342\n",
      "Epoch 26/300\n",
      " - 6s - loss: 1.4272 - acc: 0.4255 - val_loss: 1.4373 - val_acc: 0.4381\n",
      "Epoch 27/300\n",
      " - 6s - loss: 1.4248 - acc: 0.4301 - val_loss: 1.4365 - val_acc: 0.4332\n",
      "Epoch 28/300\n",
      " - 6s - loss: 1.4245 - acc: 0.4267 - val_loss: 1.4202 - val_acc: 0.4420\n",
      "Epoch 29/300\n",
      " - 7s - loss: 1.4137 - acc: 0.4291 - val_loss: 1.4057 - val_acc: 0.4366\n",
      "Epoch 30/300\n",
      " - 6s - loss: 1.4111 - acc: 0.4323 - val_loss: 1.4423 - val_acc: 0.4351\n",
      "Epoch 31/300\n",
      " - 6s - loss: 1.4056 - acc: 0.4352 - val_loss: 1.4581 - val_acc: 0.4347\n",
      "Epoch 32/300\n",
      " - 6s - loss: 1.3996 - acc: 0.4391 - val_loss: 1.4330 - val_acc: 0.4298\n",
      "Epoch 33/300\n",
      " - 6s - loss: 1.3898 - acc: 0.4355 - val_loss: 1.4675 - val_acc: 0.4214\n",
      "Epoch 34/300\n",
      " - 6s - loss: 1.3851 - acc: 0.4418 - val_loss: 1.4213 - val_acc: 0.4444\n",
      "Epoch 35/300\n",
      " - 6s - loss: 1.3766 - acc: 0.4454 - val_loss: 1.4595 - val_acc: 0.4293\n",
      "Epoch 36/300\n",
      " - 6s - loss: 1.3808 - acc: 0.4429 - val_loss: 1.4278 - val_acc: 0.4430\n",
      "Epoch 37/300\n",
      " - 6s - loss: 1.3707 - acc: 0.4491 - val_loss: 1.4473 - val_acc: 0.4195\n",
      "Epoch 38/300\n",
      " - 6s - loss: 1.3706 - acc: 0.4455 - val_loss: 1.4090 - val_acc: 0.4425\n",
      "Epoch 39/300\n",
      " - 6s - loss: 1.3688 - acc: 0.4492 - val_loss: 1.4252 - val_acc: 0.4376\n",
      "Epoch 40/300\n",
      " - 6s - loss: 1.3602 - acc: 0.4529 - val_loss: 1.4269 - val_acc: 0.4332\n",
      "Epoch 41/300\n",
      " - 6s - loss: 1.3543 - acc: 0.4563 - val_loss: 1.4385 - val_acc: 0.4391\n",
      "Epoch 42/300\n",
      " - 6s - loss: 1.3533 - acc: 0.4559 - val_loss: 1.4090 - val_acc: 0.4552\n",
      "Epoch 43/300\n",
      " - 6s - loss: 1.3543 - acc: 0.4575 - val_loss: 1.4499 - val_acc: 0.4307\n",
      "Epoch 44/300\n",
      " - 6s - loss: 1.3508 - acc: 0.4577 - val_loss: 1.4600 - val_acc: 0.4254\n",
      "Epoch 45/300\n",
      " - 7s - loss: 1.3466 - acc: 0.4605 - val_loss: 1.4342 - val_acc: 0.4415\n",
      "Epoch 46/300\n",
      " - 6s - loss: 1.3412 - acc: 0.4600 - val_loss: 1.4242 - val_acc: 0.4347\n",
      "Epoch 47/300\n",
      " - 6s - loss: 1.3318 - acc: 0.4675 - val_loss: 1.4572 - val_acc: 0.4307\n",
      "Epoch 48/300\n",
      " - 8s - loss: 1.3279 - acc: 0.4618 - val_loss: 1.4311 - val_acc: 0.4420\n",
      "Epoch 49/300\n",
      " - 6s - loss: 1.3264 - acc: 0.4678 - val_loss: 1.4010 - val_acc: 0.4557\n",
      "Epoch 50/300\n",
      " - 7s - loss: 1.3227 - acc: 0.4673 - val_loss: 1.3866 - val_acc: 0.4562\n",
      "Epoch 51/300\n",
      " - 7s - loss: 1.3141 - acc: 0.4686 - val_loss: 1.4175 - val_acc: 0.4498\n",
      "Epoch 52/300\n",
      " - 6s - loss: 1.3131 - acc: 0.4744 - val_loss: 1.4004 - val_acc: 0.4508\n",
      "Epoch 53/300\n",
      " - 6s - loss: 1.3193 - acc: 0.4746 - val_loss: 1.4380 - val_acc: 0.4435\n",
      "Epoch 54/300\n",
      " - 7s - loss: 1.3066 - acc: 0.4716 - val_loss: 1.4017 - val_acc: 0.4601\n",
      "Epoch 55/300\n",
      " - 6s - loss: 1.3040 - acc: 0.4712 - val_loss: 1.4650 - val_acc: 0.4244\n",
      "Epoch 56/300\n",
      " - 6s - loss: 1.3070 - acc: 0.4747 - val_loss: 1.4108 - val_acc: 0.4474\n",
      "Epoch 57/300\n",
      " - 6s - loss: 1.3001 - acc: 0.4779 - val_loss: 1.4044 - val_acc: 0.4567\n",
      "Epoch 58/300\n",
      " - 6s - loss: 1.2965 - acc: 0.4764 - val_loss: 1.4316 - val_acc: 0.4518\n",
      "Epoch 59/300\n",
      " - 6s - loss: 1.2893 - acc: 0.4805 - val_loss: 1.4608 - val_acc: 0.4371\n",
      "Epoch 60/300\n",
      " - 6s - loss: 1.2912 - acc: 0.4827 - val_loss: 1.4164 - val_acc: 0.4596\n",
      "Epoch 61/300\n",
      " - 7s - loss: 1.2786 - acc: 0.4844 - val_loss: 1.4088 - val_acc: 0.4523\n",
      "Epoch 62/300\n",
      " - 6s - loss: 1.2888 - acc: 0.4854 - val_loss: 1.4664 - val_acc: 0.4337\n",
      "Epoch 63/300\n",
      " - 6s - loss: 1.2830 - acc: 0.4798 - val_loss: 1.4060 - val_acc: 0.4640\n",
      "Epoch 64/300\n",
      " - 6s - loss: 1.2753 - acc: 0.4870 - val_loss: 1.4465 - val_acc: 0.4503\n",
      "Epoch 65/300\n",
      " - 7s - loss: 1.2743 - acc: 0.4873 - val_loss: 1.4338 - val_acc: 0.4361\n",
      "Epoch 66/300\n",
      " - 6s - loss: 1.2813 - acc: 0.4865 - val_loss: 1.4067 - val_acc: 0.4694\n",
      "Epoch 67/300\n",
      " - 6s - loss: 1.2690 - acc: 0.4908 - val_loss: 1.4394 - val_acc: 0.4650\n",
      "Epoch 68/300\n",
      " - 6s - loss: 1.2667 - acc: 0.4861 - val_loss: 1.4252 - val_acc: 0.4425\n",
      "Epoch 69/300\n",
      " - 6s - loss: 1.2660 - acc: 0.4879 - val_loss: 1.4193 - val_acc: 0.4547\n",
      "Epoch 70/300\n",
      " - 6s - loss: 1.2680 - acc: 0.4884 - val_loss: 1.4094 - val_acc: 0.4645\n",
      "Epoch 71/300\n",
      " - 6s - loss: 1.2600 - acc: 0.4901 - val_loss: 1.4385 - val_acc: 0.4444\n",
      "Epoch 72/300\n",
      " - 6s - loss: 1.2587 - acc: 0.4905 - val_loss: 1.4345 - val_acc: 0.4493\n",
      "Epoch 73/300\n",
      " - 6s - loss: 1.2549 - acc: 0.4965 - val_loss: 1.4245 - val_acc: 0.4630\n",
      "Epoch 74/300\n",
      " - 6s - loss: 1.2533 - acc: 0.4965 - val_loss: 1.4222 - val_acc: 0.4523\n",
      "Epoch 75/300\n",
      " - 6s - loss: 1.2536 - acc: 0.4960 - val_loss: 1.4054 - val_acc: 0.4719\n",
      "Epoch 76/300\n",
      " - 6s - loss: 1.2495 - acc: 0.4922 - val_loss: 1.4188 - val_acc: 0.4581\n",
      "Epoch 77/300\n",
      " - 6s - loss: 1.2474 - acc: 0.4957 - val_loss: 1.4199 - val_acc: 0.4552\n",
      "Epoch 78/300\n",
      " - 6s - loss: 1.2394 - acc: 0.4965 - val_loss: 1.4582 - val_acc: 0.4469\n",
      "Epoch 79/300\n",
      " - 7s - loss: 1.2428 - acc: 0.5009 - val_loss: 1.4791 - val_acc: 0.4371\n",
      "Epoch 80/300\n",
      " - 7s - loss: 1.2379 - acc: 0.5000 - val_loss: 1.4502 - val_acc: 0.4508\n",
      "Epoch 81/300\n",
      " - 6s - loss: 1.2379 - acc: 0.5043 - val_loss: 1.4507 - val_acc: 0.4454\n",
      "Epoch 82/300\n",
      " - 6s - loss: 1.2333 - acc: 0.5013 - val_loss: 1.4200 - val_acc: 0.4630\n",
      "Epoch 83/300\n",
      " - 6s - loss: 1.2349 - acc: 0.5004 - val_loss: 1.4223 - val_acc: 0.4665\n",
      "Epoch 84/300\n",
      " - 6s - loss: 1.2224 - acc: 0.5056 - val_loss: 1.5312 - val_acc: 0.4425\n",
      "Epoch 85/300\n",
      " - 6s - loss: 1.2296 - acc: 0.5026 - val_loss: 1.4557 - val_acc: 0.4410\n",
      "4-dense-64-nodes-0.001-learning_rate-16-batch_size-1554677296\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 5s - loss: 1.8431 - acc: 0.2779 - val_loss: 1.6880 - val_acc: 0.3196\n",
      "Epoch 2/300\n",
      " - 4s - loss: 1.7011 - acc: 0.3263 - val_loss: 1.6526 - val_acc: 0.3456\n",
      "Epoch 3/300\n",
      " - 4s - loss: 1.6585 - acc: 0.3411 - val_loss: 1.6563 - val_acc: 0.3279\n",
      "Epoch 4/300\n",
      " - 3s - loss: 1.6432 - acc: 0.3427 - val_loss: 1.5847 - val_acc: 0.3627\n",
      "Epoch 5/300\n",
      " - 3s - loss: 1.6223 - acc: 0.3565 - val_loss: 1.5777 - val_acc: 0.3642\n",
      "Epoch 6/300\n",
      " - 3s - loss: 1.6113 - acc: 0.3561 - val_loss: 1.6179 - val_acc: 0.3480\n",
      "Epoch 7/300\n",
      " - 3s - loss: 1.5965 - acc: 0.3625 - val_loss: 1.6039 - val_acc: 0.3647\n",
      "Epoch 8/300\n",
      " - 3s - loss: 1.5915 - acc: 0.3661 - val_loss: 1.5623 - val_acc: 0.3828\n",
      "Epoch 9/300\n",
      " - 3s - loss: 1.5814 - acc: 0.3705 - val_loss: 1.5384 - val_acc: 0.3921\n",
      "Epoch 10/300\n",
      " - 3s - loss: 1.5699 - acc: 0.3802 - val_loss: 1.5421 - val_acc: 0.3916\n",
      "Epoch 11/300\n",
      " - 3s - loss: 1.5624 - acc: 0.3758 - val_loss: 1.5307 - val_acc: 0.3911\n",
      "Epoch 12/300\n",
      " - 4s - loss: 1.5609 - acc: 0.3803 - val_loss: 1.5558 - val_acc: 0.3935\n",
      "Epoch 13/300\n",
      " - 4s - loss: 1.5504 - acc: 0.3847 - val_loss: 1.6417 - val_acc: 0.3514\n",
      "Epoch 14/300\n",
      " - 3s - loss: 1.5419 - acc: 0.3838 - val_loss: 1.5542 - val_acc: 0.3926\n",
      "Epoch 15/300\n",
      " - 3s - loss: 1.5381 - acc: 0.3863 - val_loss: 1.5650 - val_acc: 0.3872\n",
      "Epoch 16/300\n",
      " - 3s - loss: 1.5306 - acc: 0.3892 - val_loss: 1.5261 - val_acc: 0.4058\n",
      "Epoch 17/300\n",
      " - 3s - loss: 1.5271 - acc: 0.3948 - val_loss: 1.5280 - val_acc: 0.3926\n",
      "Epoch 18/300\n",
      " - 3s - loss: 1.5134 - acc: 0.3964 - val_loss: 1.5214 - val_acc: 0.4087\n",
      "Epoch 19/300\n",
      " - 3s - loss: 1.5090 - acc: 0.4010 - val_loss: 1.5126 - val_acc: 0.4028\n",
      "Epoch 20/300\n",
      " - 3s - loss: 1.4995 - acc: 0.4041 - val_loss: 1.5152 - val_acc: 0.4116\n",
      "Epoch 21/300\n",
      " - 3s - loss: 1.4951 - acc: 0.4032 - val_loss: 1.4825 - val_acc: 0.4180\n",
      "Epoch 22/300\n",
      " - 3s - loss: 1.4787 - acc: 0.4087 - val_loss: 1.5029 - val_acc: 0.4097\n",
      "Epoch 23/300\n",
      " - 3s - loss: 1.4755 - acc: 0.4073 - val_loss: 1.4743 - val_acc: 0.4205\n",
      "Epoch 24/300\n",
      " - 3s - loss: 1.4682 - acc: 0.4127 - val_loss: 1.4583 - val_acc: 0.4185\n",
      "Epoch 25/300\n",
      " - 3s - loss: 1.4620 - acc: 0.4163 - val_loss: 1.4764 - val_acc: 0.4229\n",
      "Epoch 26/300\n",
      " - 3s - loss: 1.4567 - acc: 0.4182 - val_loss: 1.4722 - val_acc: 0.4224\n",
      "Epoch 27/300\n",
      " - 3s - loss: 1.4482 - acc: 0.4194 - val_loss: 1.4508 - val_acc: 0.4317\n",
      "Epoch 28/300\n",
      " - 3s - loss: 1.4452 - acc: 0.4190 - val_loss: 1.4557 - val_acc: 0.4307\n",
      "Epoch 29/300\n",
      " - 3s - loss: 1.4341 - acc: 0.4247 - val_loss: 1.4651 - val_acc: 0.4200\n",
      "Epoch 30/300\n",
      " - 3s - loss: 1.4326 - acc: 0.4279 - val_loss: 1.4853 - val_acc: 0.4116\n",
      "Epoch 31/300\n",
      " - 3s - loss: 1.4253 - acc: 0.4313 - val_loss: 1.4250 - val_acc: 0.4366\n",
      "Epoch 32/300\n",
      " - 3s - loss: 1.4209 - acc: 0.4306 - val_loss: 1.4347 - val_acc: 0.4312\n",
      "Epoch 33/300\n",
      " - 3s - loss: 1.4164 - acc: 0.4348 - val_loss: 1.4403 - val_acc: 0.4332\n",
      "Epoch 34/300\n",
      " - 3s - loss: 1.4053 - acc: 0.4362 - val_loss: 1.4726 - val_acc: 0.4209\n",
      "Epoch 35/300\n",
      " - 3s - loss: 1.4065 - acc: 0.4358 - val_loss: 1.5112 - val_acc: 0.3935\n",
      "Epoch 36/300\n",
      " - 3s - loss: 1.4001 - acc: 0.4353 - val_loss: 1.4344 - val_acc: 0.4244\n",
      "Epoch 37/300\n",
      " - 3s - loss: 1.3942 - acc: 0.4419 - val_loss: 1.4414 - val_acc: 0.4371\n",
      "Epoch 38/300\n",
      " - 3s - loss: 1.3940 - acc: 0.4424 - val_loss: 1.4277 - val_acc: 0.4381\n",
      "Epoch 39/300\n",
      " - 3s - loss: 1.3829 - acc: 0.4443 - val_loss: 1.4227 - val_acc: 0.4552\n",
      "Epoch 40/300\n",
      " - 3s - loss: 1.3853 - acc: 0.4459 - val_loss: 1.4603 - val_acc: 0.4327\n",
      "Epoch 41/300\n",
      " - 3s - loss: 1.3800 - acc: 0.4482 - val_loss: 1.4427 - val_acc: 0.4356\n",
      "Epoch 42/300\n",
      " - 3s - loss: 1.3728 - acc: 0.4488 - val_loss: 1.4216 - val_acc: 0.4410\n",
      "Epoch 43/300\n",
      " - 3s - loss: 1.3703 - acc: 0.4539 - val_loss: 1.4027 - val_acc: 0.4640\n",
      "Epoch 44/300\n",
      " - 3s - loss: 1.3644 - acc: 0.4539 - val_loss: 1.4122 - val_acc: 0.4537\n",
      "Epoch 45/300\n",
      " - 3s - loss: 1.3658 - acc: 0.4492 - val_loss: 1.4389 - val_acc: 0.4366\n",
      "Epoch 46/300\n",
      " - 3s - loss: 1.3516 - acc: 0.4566 - val_loss: 1.4185 - val_acc: 0.4552\n",
      "Epoch 47/300\n",
      " - 3s - loss: 1.3450 - acc: 0.4603 - val_loss: 1.3952 - val_acc: 0.4694\n",
      "Epoch 48/300\n",
      " - 3s - loss: 1.3430 - acc: 0.4584 - val_loss: 1.4057 - val_acc: 0.4498\n",
      "Epoch 49/300\n",
      " - 3s - loss: 1.3399 - acc: 0.4637 - val_loss: 1.4180 - val_acc: 0.4474\n",
      "Epoch 50/300\n",
      " - 3s - loss: 1.3512 - acc: 0.4593 - val_loss: 1.4261 - val_acc: 0.4410\n",
      "Epoch 51/300\n",
      " - 3s - loss: 1.3404 - acc: 0.4592 - val_loss: 1.4390 - val_acc: 0.4351\n",
      "Epoch 52/300\n",
      " - 3s - loss: 1.3266 - acc: 0.4692 - val_loss: 1.3867 - val_acc: 0.4630\n",
      "Epoch 53/300\n",
      " - 3s - loss: 1.3287 - acc: 0.4656 - val_loss: 1.4140 - val_acc: 0.4376\n",
      "Epoch 54/300\n",
      " - 3s - loss: 1.3236 - acc: 0.4642 - val_loss: 1.4573 - val_acc: 0.4273\n",
      "Epoch 55/300\n",
      " - 3s - loss: 1.3213 - acc: 0.4696 - val_loss: 1.4008 - val_acc: 0.4586\n",
      "Epoch 56/300\n",
      " - 3s - loss: 1.3145 - acc: 0.4724 - val_loss: 1.4127 - val_acc: 0.4444\n",
      "Epoch 57/300\n",
      " - 3s - loss: 1.3134 - acc: 0.4722 - val_loss: 1.3924 - val_acc: 0.4674\n",
      "4-dense-64-nodes-0.001-learning_rate-32-batch_size-1554677478\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 1.8643 - acc: 0.2733 - val_loss: 1.6823 - val_acc: 0.3304\n",
      "Epoch 2/300\n",
      " - 2s - loss: 1.6975 - acc: 0.3318 - val_loss: 1.6444 - val_acc: 0.3500\n",
      "Epoch 3/300\n",
      " - 2s - loss: 1.6581 - acc: 0.3449 - val_loss: 1.6477 - val_acc: 0.3289\n",
      "Epoch 4/300\n",
      " - 2s - loss: 1.6346 - acc: 0.3514 - val_loss: 1.6069 - val_acc: 0.3558\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.6176 - acc: 0.3615 - val_loss: 1.5756 - val_acc: 0.3764\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.6068 - acc: 0.3603 - val_loss: 1.5629 - val_acc: 0.3725\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.5972 - acc: 0.3664 - val_loss: 1.5552 - val_acc: 0.3852\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5898 - acc: 0.3686 - val_loss: 1.5462 - val_acc: 0.3916\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5793 - acc: 0.3740 - val_loss: 1.5469 - val_acc: 0.3862\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5733 - acc: 0.3781 - val_loss: 1.5403 - val_acc: 0.3911\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.5660 - acc: 0.3802 - val_loss: 1.5607 - val_acc: 0.3740\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.5580 - acc: 0.3839 - val_loss: 1.5483 - val_acc: 0.3891\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.5501 - acc: 0.3874 - val_loss: 1.5255 - val_acc: 0.3984\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.5446 - acc: 0.3886 - val_loss: 1.5149 - val_acc: 0.3935\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.5366 - acc: 0.3953 - val_loss: 1.5048 - val_acc: 0.3945\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.5297 - acc: 0.3961 - val_loss: 1.5237 - val_acc: 0.4136\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.5269 - acc: 0.3991 - val_loss: 1.4961 - val_acc: 0.4121\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.5109 - acc: 0.4013 - val_loss: 1.5052 - val_acc: 0.4033\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.5100 - acc: 0.4000 - val_loss: 1.5012 - val_acc: 0.4092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300\n",
      " - 2s - loss: 1.4969 - acc: 0.4066 - val_loss: 1.4788 - val_acc: 0.4244\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.4917 - acc: 0.4101 - val_loss: 1.4971 - val_acc: 0.4161\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.4847 - acc: 0.4101 - val_loss: 1.4736 - val_acc: 0.4234\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.4795 - acc: 0.4088 - val_loss: 1.4708 - val_acc: 0.4146\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.4722 - acc: 0.4156 - val_loss: 1.5701 - val_acc: 0.3744\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.4717 - acc: 0.4142 - val_loss: 1.4558 - val_acc: 0.4293\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.4557 - acc: 0.4207 - val_loss: 1.4650 - val_acc: 0.4219\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.4519 - acc: 0.4183 - val_loss: 1.4355 - val_acc: 0.4459\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.4457 - acc: 0.4233 - val_loss: 1.4801 - val_acc: 0.4077\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.4472 - acc: 0.4218 - val_loss: 1.4432 - val_acc: 0.4307\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.4353 - acc: 0.4276 - val_loss: 1.4362 - val_acc: 0.4288\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.4327 - acc: 0.4282 - val_loss: 1.4558 - val_acc: 0.4205\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.4255 - acc: 0.4294 - val_loss: 1.4342 - val_acc: 0.4342\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.4263 - acc: 0.4358 - val_loss: 1.4441 - val_acc: 0.4332\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.4186 - acc: 0.4341 - val_loss: 1.4448 - val_acc: 0.4273\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.4103 - acc: 0.4347 - val_loss: 1.4754 - val_acc: 0.4043\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.4130 - acc: 0.4348 - val_loss: 1.4734 - val_acc: 0.4254\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.4129 - acc: 0.4352 - val_loss: 1.4153 - val_acc: 0.4400\n",
      "4-dense-64-nodes-0.001-learning_rate-64-batch_size-1554677549\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 1.9232 - acc: 0.2572 - val_loss: 1.7259 - val_acc: 0.3010\n",
      "Epoch 2/300\n",
      " - 1s - loss: 1.7161 - acc: 0.3214 - val_loss: 1.6659 - val_acc: 0.3314\n",
      "Epoch 3/300\n",
      " - 1s - loss: 1.6797 - acc: 0.3390 - val_loss: 1.6480 - val_acc: 0.3417\n",
      "Epoch 4/300\n",
      " - 1s - loss: 1.6552 - acc: 0.3465 - val_loss: 1.6184 - val_acc: 0.3651\n",
      "Epoch 5/300\n",
      " - 1s - loss: 1.6404 - acc: 0.3529 - val_loss: 1.6084 - val_acc: 0.3612\n",
      "Epoch 6/300\n",
      " - 1s - loss: 1.6217 - acc: 0.3591 - val_loss: 1.5891 - val_acc: 0.3671\n",
      "Epoch 7/300\n",
      " - 1s - loss: 1.6120 - acc: 0.3648 - val_loss: 1.5834 - val_acc: 0.3744\n",
      "Epoch 8/300\n",
      " - 1s - loss: 1.6007 - acc: 0.3592 - val_loss: 1.5793 - val_acc: 0.3813\n",
      "Epoch 9/300\n",
      " - 1s - loss: 1.5946 - acc: 0.3649 - val_loss: 1.6071 - val_acc: 0.3544\n",
      "Epoch 10/300\n",
      " - 1s - loss: 1.5872 - acc: 0.3694 - val_loss: 1.5718 - val_acc: 0.3700\n",
      "Epoch 11/300\n",
      " - 1s - loss: 1.5858 - acc: 0.3704 - val_loss: 1.6457 - val_acc: 0.3417\n",
      "Epoch 12/300\n",
      " - 1s - loss: 1.5768 - acc: 0.3765 - val_loss: 1.5811 - val_acc: 0.3837\n",
      "Epoch 13/300\n",
      " - 1s - loss: 1.5681 - acc: 0.3794 - val_loss: 1.5490 - val_acc: 0.3896\n",
      "Epoch 14/300\n",
      " - 1s - loss: 1.5593 - acc: 0.3811 - val_loss: 1.5347 - val_acc: 0.4033\n",
      "Epoch 15/300\n",
      " - 1s - loss: 1.5570 - acc: 0.3823 - val_loss: 1.5489 - val_acc: 0.3862\n",
      "Epoch 16/300\n",
      " - 1s - loss: 1.5532 - acc: 0.3850 - val_loss: 1.5411 - val_acc: 0.3886\n",
      "Epoch 17/300\n",
      " - 1s - loss: 1.5533 - acc: 0.3868 - val_loss: 1.5589 - val_acc: 0.3744\n",
      "Epoch 18/300\n",
      " - 1s - loss: 1.5405 - acc: 0.3890 - val_loss: 1.5209 - val_acc: 0.3955\n",
      "Epoch 19/300\n",
      " - 1s - loss: 1.5419 - acc: 0.3890 - val_loss: 1.6109 - val_acc: 0.3754\n",
      "Epoch 20/300\n",
      " - 1s - loss: 1.5330 - acc: 0.3907 - val_loss: 1.5157 - val_acc: 0.4038\n",
      "Epoch 21/300\n",
      " - 1s - loss: 1.5291 - acc: 0.3932 - val_loss: 1.5232 - val_acc: 0.4023\n",
      "Epoch 22/300\n",
      " - 1s - loss: 1.5245 - acc: 0.3963 - val_loss: 1.5040 - val_acc: 0.4165\n",
      "Epoch 23/300\n",
      " - 1s - loss: 1.5194 - acc: 0.3992 - val_loss: 1.5227 - val_acc: 0.3999\n",
      "Epoch 24/300\n",
      " - 1s - loss: 1.5175 - acc: 0.3962 - val_loss: 1.5321 - val_acc: 0.3960\n",
      "Epoch 25/300\n",
      " - 1s - loss: 1.5143 - acc: 0.3962 - val_loss: 1.4964 - val_acc: 0.4146\n",
      "Epoch 26/300\n",
      " - 1s - loss: 1.5091 - acc: 0.3984 - val_loss: 1.5126 - val_acc: 0.4028\n",
      "Epoch 27/300\n",
      " - 1s - loss: 1.5066 - acc: 0.4027 - val_loss: 1.4897 - val_acc: 0.4141\n",
      "Epoch 28/300\n",
      " - 1s - loss: 1.4947 - acc: 0.4088 - val_loss: 1.4919 - val_acc: 0.4170\n",
      "Epoch 29/300\n",
      " - 1s - loss: 1.4899 - acc: 0.4101 - val_loss: 1.4939 - val_acc: 0.4195\n",
      "Epoch 30/300\n",
      " - 1s - loss: 1.4861 - acc: 0.4077 - val_loss: 1.4977 - val_acc: 0.4087\n",
      "Epoch 31/300\n",
      " - 1s - loss: 1.4892 - acc: 0.4058 - val_loss: 1.5110 - val_acc: 0.3926\n",
      "Epoch 32/300\n",
      " - 1s - loss: 1.4738 - acc: 0.4134 - val_loss: 1.4958 - val_acc: 0.4165\n",
      "Epoch 33/300\n",
      " - 1s - loss: 1.4728 - acc: 0.4094 - val_loss: 1.4725 - val_acc: 0.4249\n",
      "Epoch 34/300\n",
      " - 1s - loss: 1.4681 - acc: 0.4162 - val_loss: 1.4581 - val_acc: 0.4258\n",
      "Epoch 35/300\n",
      " - 1s - loss: 1.4656 - acc: 0.4190 - val_loss: 1.4627 - val_acc: 0.4161\n",
      "Epoch 36/300\n",
      " - 1s - loss: 1.4587 - acc: 0.4183 - val_loss: 1.4868 - val_acc: 0.4112\n",
      "Epoch 37/300\n",
      " - 1s - loss: 1.4531 - acc: 0.4224 - val_loss: 1.4689 - val_acc: 0.4170\n",
      "Epoch 38/300\n",
      " - 1s - loss: 1.4566 - acc: 0.4210 - val_loss: 1.4596 - val_acc: 0.4185\n",
      "Epoch 39/300\n",
      " - 1s - loss: 1.4481 - acc: 0.4213 - val_loss: 1.5020 - val_acc: 0.4028\n",
      "Epoch 40/300\n",
      " - 1s - loss: 1.4514 - acc: 0.4238 - val_loss: 1.4568 - val_acc: 0.4234\n",
      "Epoch 41/300\n",
      " - 1s - loss: 1.4387 - acc: 0.4232 - val_loss: 1.4751 - val_acc: 0.4112\n",
      "Epoch 42/300\n",
      " - 1s - loss: 1.4380 - acc: 0.4246 - val_loss: 1.5268 - val_acc: 0.4053\n",
      "Epoch 43/300\n",
      " - 1s - loss: 1.4339 - acc: 0.4279 - val_loss: 1.4439 - val_acc: 0.4381\n",
      "Epoch 44/300\n",
      " - 1s - loss: 1.4302 - acc: 0.4294 - val_loss: 1.4622 - val_acc: 0.4097\n",
      "Epoch 45/300\n",
      " - 1s - loss: 1.4307 - acc: 0.4309 - val_loss: 1.4368 - val_acc: 0.4200\n",
      "Epoch 46/300\n",
      " - 1s - loss: 1.4251 - acc: 0.4303 - val_loss: 1.4272 - val_acc: 0.4371\n",
      "Epoch 47/300\n",
      " - 1s - loss: 1.4309 - acc: 0.4269 - val_loss: 1.4618 - val_acc: 0.4288\n",
      "Epoch 48/300\n",
      " - 1s - loss: 1.4096 - acc: 0.4368 - val_loss: 1.4254 - val_acc: 0.4317\n",
      "Epoch 49/300\n",
      " - 1s - loss: 1.4196 - acc: 0.4342 - val_loss: 1.4348 - val_acc: 0.4371\n",
      "Epoch 50/300\n",
      " - 1s - loss: 1.4113 - acc: 0.4334 - val_loss: 1.4431 - val_acc: 0.4307\n",
      "Epoch 51/300\n",
      " - 1s - loss: 1.4093 - acc: 0.4408 - val_loss: 1.4449 - val_acc: 0.4258\n",
      "Epoch 52/300\n",
      " - 1s - loss: 1.3976 - acc: 0.4459 - val_loss: 1.4473 - val_acc: 0.4288\n",
      "Epoch 53/300\n",
      " - 1s - loss: 1.3938 - acc: 0.4453 - val_loss: 1.4542 - val_acc: 0.4376\n",
      "4-dense-64-nodes-0.001-learning_rate-128-batch_size-1554677605\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,706\n",
      "Trainable params: 13,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 2043 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 2.0064 - acc: 0.2296 - val_loss: 1.7333 - val_acc: 0.3074\n",
      "Epoch 2/300\n",
      " - 1s - loss: 1.7342 - acc: 0.3218 - val_loss: 1.6838 - val_acc: 0.3338\n",
      "Epoch 3/300\n",
      " - 1s - loss: 1.7002 - acc: 0.3266 - val_loss: 1.6559 - val_acc: 0.3421\n",
      "Epoch 4/300\n",
      " - 1s - loss: 1.6701 - acc: 0.3403 - val_loss: 1.6286 - val_acc: 0.3461\n",
      "Epoch 5/300\n",
      " - 1s - loss: 1.6529 - acc: 0.3485 - val_loss: 1.6192 - val_acc: 0.3446\n",
      "Epoch 6/300\n",
      " - 1s - loss: 1.6357 - acc: 0.3527 - val_loss: 1.6103 - val_acc: 0.3568\n",
      "Epoch 7/300\n",
      " - 1s - loss: 1.6228 - acc: 0.3608 - val_loss: 1.6141 - val_acc: 0.3534\n",
      "Epoch 8/300\n",
      " - 1s - loss: 1.6219 - acc: 0.3626 - val_loss: 1.5853 - val_acc: 0.3529\n",
      "Epoch 9/300\n",
      " - 1s - loss: 1.5985 - acc: 0.3712 - val_loss: 1.5782 - val_acc: 0.3798\n",
      "Epoch 10/300\n",
      " - 1s - loss: 1.6045 - acc: 0.3649 - val_loss: 1.5741 - val_acc: 0.3803\n",
      "Epoch 11/300\n",
      " - 1s - loss: 1.5878 - acc: 0.3745 - val_loss: 1.5615 - val_acc: 0.3872\n",
      "Epoch 12/300\n",
      " - 1s - loss: 1.5792 - acc: 0.3761 - val_loss: 1.5625 - val_acc: 0.3921\n",
      "Epoch 13/300\n",
      " - 1s - loss: 1.5818 - acc: 0.3765 - val_loss: 1.5736 - val_acc: 0.3740\n",
      "Epoch 14/300\n",
      " - 1s - loss: 1.5756 - acc: 0.3764 - val_loss: 1.5629 - val_acc: 0.3823\n",
      "Epoch 15/300\n",
      " - 1s - loss: 1.5710 - acc: 0.3797 - val_loss: 1.5415 - val_acc: 0.3940\n",
      "Epoch 16/300\n",
      " - 1s - loss: 1.5666 - acc: 0.3809 - val_loss: 1.5427 - val_acc: 0.3882\n",
      "Epoch 17/300\n",
      " - 1s - loss: 1.5538 - acc: 0.3887 - val_loss: 1.5333 - val_acc: 0.3930\n",
      "Epoch 18/300\n",
      " - 1s - loss: 1.5547 - acc: 0.3857 - val_loss: 1.5370 - val_acc: 0.3940\n",
      "Epoch 19/300\n",
      " - 1s - loss: 1.5518 - acc: 0.3835 - val_loss: 1.5497 - val_acc: 0.3798\n",
      "Epoch 20/300\n",
      " - 1s - loss: 1.5422 - acc: 0.3909 - val_loss: 1.5235 - val_acc: 0.3906\n",
      "Epoch 21/300\n",
      " - 1s - loss: 1.5409 - acc: 0.3901 - val_loss: 1.5266 - val_acc: 0.4063\n",
      "Epoch 22/300\n",
      " - 1s - loss: 1.5397 - acc: 0.3945 - val_loss: 1.5477 - val_acc: 0.4009\n",
      "Epoch 23/300\n",
      " - 1s - loss: 1.5375 - acc: 0.3899 - val_loss: 1.5324 - val_acc: 0.3965\n",
      "Epoch 24/300\n",
      " - 1s - loss: 1.5312 - acc: 0.3934 - val_loss: 1.5253 - val_acc: 0.3921\n",
      "Epoch 25/300\n",
      " - 1s - loss: 1.5293 - acc: 0.3910 - val_loss: 1.5546 - val_acc: 0.3911\n",
      "Epoch 26/300\n",
      " - 1s - loss: 1.5307 - acc: 0.3945 - val_loss: 1.5745 - val_acc: 0.3764\n",
      "Epoch 27/300\n",
      " - 1s - loss: 1.5271 - acc: 0.3925 - val_loss: 1.5238 - val_acc: 0.4048\n",
      "Epoch 28/300\n",
      " - 1s - loss: 1.5236 - acc: 0.3955 - val_loss: 1.5109 - val_acc: 0.4092\n",
      "Epoch 29/300\n",
      " - 1s - loss: 1.5165 - acc: 0.3955 - val_loss: 1.5067 - val_acc: 0.4102\n",
      "Epoch 30/300\n",
      " - 1s - loss: 1.5132 - acc: 0.3962 - val_loss: 1.5028 - val_acc: 0.4116\n",
      "Epoch 31/300\n",
      " - 1s - loss: 1.5112 - acc: 0.4057 - val_loss: 1.5328 - val_acc: 0.4009\n",
      "Epoch 32/300\n",
      " - 1s - loss: 1.5109 - acc: 0.3957 - val_loss: 1.5018 - val_acc: 0.4151\n",
      "Epoch 33/300\n",
      " - 1s - loss: 1.5087 - acc: 0.4036 - val_loss: 1.5036 - val_acc: 0.4004\n",
      "Epoch 34/300\n",
      " - 1s - loss: 1.4991 - acc: 0.4044 - val_loss: 1.5072 - val_acc: 0.4072\n",
      "Epoch 35/300\n",
      " - 1s - loss: 1.4998 - acc: 0.4020 - val_loss: 1.4965 - val_acc: 0.4136\n",
      "Epoch 36/300\n",
      " - 1s - loss: 1.4944 - acc: 0.4104 - val_loss: 1.5082 - val_acc: 0.4014\n",
      "Epoch 37/300\n",
      " - 1s - loss: 1.4947 - acc: 0.4062 - val_loss: 1.4973 - val_acc: 0.4058\n",
      "Epoch 38/300\n",
      " - 1s - loss: 1.4990 - acc: 0.4089 - val_loss: 1.5796 - val_acc: 0.3671\n",
      "Epoch 39/300\n",
      " - 1s - loss: 1.4907 - acc: 0.4081 - val_loss: 1.4930 - val_acc: 0.4136\n",
      "Epoch 40/300\n",
      " - 1s - loss: 1.4860 - acc: 0.4142 - val_loss: 1.4824 - val_acc: 0.4146\n",
      "Epoch 41/300\n",
      " - 1s - loss: 1.4929 - acc: 0.4096 - val_loss: 1.5071 - val_acc: 0.4195\n",
      "Epoch 42/300\n",
      " - 1s - loss: 1.4838 - acc: 0.4133 - val_loss: 1.4828 - val_acc: 0.4209\n",
      "Epoch 43/300\n",
      " - 1s - loss: 1.4791 - acc: 0.4166 - val_loss: 1.5326 - val_acc: 0.3960\n",
      "Epoch 44/300\n",
      " - 1s - loss: 1.4767 - acc: 0.4177 - val_loss: 1.4939 - val_acc: 0.4053\n",
      "Epoch 45/300\n",
      " - 1s - loss: 1.4777 - acc: 0.4125 - val_loss: 1.4878 - val_acc: 0.4214\n",
      "Epoch 46/300\n",
      " - 1s - loss: 1.4717 - acc: 0.4145 - val_loss: 1.4978 - val_acc: 0.4063\n",
      "Epoch 47/300\n",
      " - 1s - loss: 1.4688 - acc: 0.4171 - val_loss: 1.4751 - val_acc: 0.4146\n",
      "Epoch 48/300\n",
      " - 1s - loss: 1.4643 - acc: 0.4180 - val_loss: 1.4757 - val_acc: 0.4205\n",
      "Epoch 49/300\n",
      " - 1s - loss: 1.4627 - acc: 0.4233 - val_loss: 1.4897 - val_acc: 0.4146\n",
      "Epoch 50/300\n",
      " - 1s - loss: 1.4608 - acc: 0.4214 - val_loss: 1.5233 - val_acc: 0.4009\n",
      "Epoch 51/300\n",
      " - 1s - loss: 1.4568 - acc: 0.4254 - val_loss: 1.4757 - val_acc: 0.4268\n",
      "Epoch 52/300\n",
      " - 1s - loss: 1.4653 - acc: 0.4219 - val_loss: 1.4786 - val_acc: 0.4229\n",
      "Epoch 53/300\n",
      " - 1s - loss: 1.4583 - acc: 0.4200 - val_loss: 1.4770 - val_acc: 0.4254\n",
      "Epoch 54/300\n",
      " - 1s - loss: 1.4529 - acc: 0.4203 - val_loss: 1.5165 - val_acc: 0.4014\n",
      "Epoch 55/300\n",
      " - 1s - loss: 1.4514 - acc: 0.4231 - val_loss: 1.4717 - val_acc: 0.4244\n",
      "Epoch 56/300\n",
      " - 1s - loss: 1.4515 - acc: 0.4255 - val_loss: 1.4545 - val_acc: 0.4229\n",
      "Epoch 57/300\n",
      " - 1s - loss: 1.4431 - acc: 0.4263 - val_loss: 1.4767 - val_acc: 0.4214\n",
      "Epoch 58/300\n",
      " - 1s - loss: 1.4372 - acc: 0.4282 - val_loss: 1.4587 - val_acc: 0.4273\n",
      "Epoch 59/300\n",
      " - 1s - loss: 1.4505 - acc: 0.4237 - val_loss: 1.4706 - val_acc: 0.4234\n",
      "Epoch 60/300\n",
      " - 1s - loss: 1.4528 - acc: 0.4225 - val_loss: 1.4602 - val_acc: 0.4200\n",
      "Epoch 61/300\n",
      " - 1s - loss: 1.4342 - acc: 0.4298 - val_loss: 1.4578 - val_acc: 0.4268\n",
      "Epoch 62/300\n",
      " - 1s - loss: 1.4329 - acc: 0.4326 - val_loss: 1.4633 - val_acc: 0.4283\n",
      "Epoch 63/300\n",
      " - 1s - loss: 1.4298 - acc: 0.4294 - val_loss: 1.4556 - val_acc: 0.4298\n",
      "Epoch 64/300\n",
      " - 1s - loss: 1.4336 - acc: 0.4259 - val_loss: 1.4563 - val_acc: 0.4258\n",
      "Epoch 65/300\n",
      " - 1s - loss: 1.4237 - acc: 0.4389 - val_loss: 1.4572 - val_acc: 0.4258\n",
      "Epoch 66/300\n",
      " - 1s - loss: 1.4256 - acc: 0.4314 - val_loss: 1.4693 - val_acc: 0.4209\n",
      "Epoch 67/300\n",
      " - 1s - loss: 1.4336 - acc: 0.4301 - val_loss: 1.4508 - val_acc: 0.4298\n",
      "Epoch 68/300\n",
      " - 1s - loss: 1.4201 - acc: 0.4298 - val_loss: 1.4835 - val_acc: 0.4190\n",
      "Epoch 69/300\n",
      " - 1s - loss: 1.4190 - acc: 0.4351 - val_loss: 1.4801 - val_acc: 0.4224\n",
      "Epoch 70/300\n",
      " - 1s - loss: 1.4211 - acc: 0.4338 - val_loss: 1.4482 - val_acc: 0.4322\n",
      "Epoch 71/300\n",
      " - 1s - loss: 1.4159 - acc: 0.4359 - val_loss: 1.4469 - val_acc: 0.4342\n",
      "Epoch 72/300\n",
      " - 1s - loss: 1.4147 - acc: 0.4369 - val_loss: 1.4390 - val_acc: 0.4273\n",
      "Epoch 73/300\n",
      " - 1s - loss: 1.4094 - acc: 0.4405 - val_loss: 1.4589 - val_acc: 0.4219\n",
      "Epoch 74/300\n",
      " - 1s - loss: 1.4109 - acc: 0.4366 - val_loss: 1.4855 - val_acc: 0.4200\n",
      "Epoch 75/300\n",
      " - 1s - loss: 1.4333 - acc: 0.4295 - val_loss: 1.5123 - val_acc: 0.3950\n",
      "Epoch 76/300\n",
      " - 1s - loss: 1.4042 - acc: 0.4430 - val_loss: 1.4341 - val_acc: 0.4410\n",
      "Epoch 77/300\n",
      " - 1s - loss: 1.4117 - acc: 0.4355 - val_loss: 1.4454 - val_acc: 0.4317\n",
      "Epoch 78/300\n",
      " - 1s - loss: 1.4011 - acc: 0.4438 - val_loss: 1.4365 - val_acc: 0.4376\n",
      "Epoch 79/300\n",
      " - 1s - loss: 1.4055 - acc: 0.4369 - val_loss: 1.4331 - val_acc: 0.4415\n",
      "Epoch 80/300\n",
      " - 1s - loss: 1.3926 - acc: 0.4440 - val_loss: 1.4338 - val_acc: 0.4386\n",
      "Epoch 81/300\n",
      " - 1s - loss: 1.3945 - acc: 0.4447 - val_loss: 1.4504 - val_acc: 0.4366\n",
      "Epoch 82/300\n",
      " - 1s - loss: 1.3950 - acc: 0.4433 - val_loss: 1.4606 - val_acc: 0.4205\n",
      "Epoch 83/300\n",
      " - 1s - loss: 1.4015 - acc: 0.4430 - val_loss: 1.4391 - val_acc: 0.4395\n",
      "Epoch 84/300\n",
      " - 1s - loss: 1.3897 - acc: 0.4463 - val_loss: 1.4573 - val_acc: 0.4200\n",
      "Epoch 85/300\n",
      " - 1s - loss: 1.3908 - acc: 0.4447 - val_loss: 1.4328 - val_acc: 0.4405\n",
      "Epoch 86/300\n",
      " - 1s - loss: 1.3902 - acc: 0.4508 - val_loss: 1.4369 - val_acc: 0.4484\n",
      "Epoch 87/300\n",
      " - 1s - loss: 1.3898 - acc: 0.4416 - val_loss: 1.4319 - val_acc: 0.4376\n",
      "Epoch 88/300\n",
      " - 1s - loss: 1.3890 - acc: 0.4462 - val_loss: 1.4304 - val_acc: 0.4356\n",
      "Epoch 89/300\n",
      " - 1s - loss: 1.3855 - acc: 0.4512 - val_loss: 1.4351 - val_acc: 0.4395\n",
      "Epoch 90/300\n",
      " - 1s - loss: 1.3842 - acc: 0.4476 - val_loss: 1.4338 - val_acc: 0.4351\n",
      "Epoch 91/300\n",
      " - 1s - loss: 1.3857 - acc: 0.4462 - val_loss: 1.4604 - val_acc: 0.4322\n",
      "Epoch 92/300\n",
      " - 1s - loss: 1.3770 - acc: 0.4517 - val_loss: 1.4287 - val_acc: 0.4381\n",
      "Epoch 93/300\n",
      " - 1s - loss: 1.3768 - acc: 0.4513 - val_loss: 1.4218 - val_acc: 0.4430\n",
      "Epoch 94/300\n",
      " - 1s - loss: 1.3710 - acc: 0.4557 - val_loss: 1.4428 - val_acc: 0.4391\n",
      "Epoch 95/300\n",
      " - 1s - loss: 1.3679 - acc: 0.4584 - val_loss: 1.4234 - val_acc: 0.4459\n",
      "Epoch 96/300\n",
      " - 1s - loss: 1.3747 - acc: 0.4539 - val_loss: 1.4371 - val_acc: 0.4479\n"
     ]
    }
   ],
   "source": [
    "dense_layers = [3,4]\n",
    "layer_sizes = [64]\n",
    "learning_rates = [0.001]\n",
    "#learning_rates = [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
    "batch_sizes = [2,4,8,16,32,64,128]\n",
    "\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "        \n",
    "                NAME = \"{}-dense-{}-nodes-{}-learning_rate-{}-batch_size-{}\".format(dense_layer, layer_size, learning_rate,batch_size, int(time()))\n",
    "                print(NAME)\n",
    "                \n",
    "                mlp = Sequential()\n",
    "                \n",
    "                mlp.add(Dense(layer_size, input_dim=INPUTS))\n",
    "                mlp.add(Activation('relu'))\n",
    "                \n",
    "                for l in range(dense_layer-1):\n",
    "                    mlp.add(Dense(layer_size))\n",
    "                    mlp.add(Activation('relu'))\n",
    "                    \n",
    "                # Final layer\n",
    "                mlp.add(Dense(OUTPUTS))\n",
    "                mlp.add(Activation('softmax'))\n",
    "                \n",
    "                tensorboard = TensorBoard(log_dir=\"BatchSize/{}\".format(NAME))\n",
    "                \n",
    "                \n",
    "                opt = optimizers.Adam(lr=learning_rate)\n",
    "                mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                mlp.summary()    \n",
    "                mlp.fit(x_train, t_train, batch_size=batch_size, epochs=300, verbose=2, validation_data=(x_dev, t_dev), callbacks=[tensorboard, earlystop])\n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Results:\n",
    "    \n",
    "    * 4x64 --> 16 batch-size\n",
    "    * 4x64 --> 8 batch-size\n",
    "    * 4x64 --> 32 batch-size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "mlp = Sequential()\n",
    "\n",
    "# Middle layers\n",
    "\n",
    "# First\n",
    "mlp.add(Dense(n_neurons_per_layer[0], input_dim=INPUTS))\n",
    "mlp.add(Activation('relu'))\n",
    "mlp.add(Dropout(0.2))\n",
    "\n",
    "# Second\n",
    "mlp.add(Dense(n_neurons_per_layer[1]))\n",
    "mlp.add(Activation('relu'))\n",
    "mlp.add(Dropout(0.2))\n",
    "\n",
    "# Second\n",
    "mlp.add(Dense(n_neurons_per_layer[2]))\n",
    "mlp.add(Activation('relu'))\n",
    "mlp.add(Dropout(0.2))\n",
    "\n",
    "# Final layer\n",
    "mlp.add(Dense(OUTPUTS))\n",
    "mlp.add(Activation('softmax'))\n",
    "\n",
    "opt = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mlp.fit(x_train, t_train, batch_size=batch_size, epochs=n_epochs, verbose=2, validation_data=(x_dev, t_dev), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "loss, acc = mlp.evaluate(x_test, t_test, verbose=0)\n",
    "end = time()\n",
    "print('MLP took ' + str(end - start) + ' seconds')\n",
    "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(x_train, t_train, batch_size=batch_size, epochs=n_epochs, verbose=2, validation_data=(x_dev, t_dev), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
